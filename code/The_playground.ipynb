{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place order': 'A', 'pick item': 'B', 'confirm order': 'C', 'item out of stock': 'D', 'reorder item': 'E', 'pay order': 'F', 'create package': 'G', 'send package': 'H', 'failed delivery': 'I', 'package delivered': 'J', 'payment reminder': 'K'}\n",
      "{'Marco Pegoraro': 'a', 'Gyunam Park': 'b', 'Majid Rafiei': 'c', 'Junxiong Gao': 'd', 'Seran Uysal': 'e', 'Christina Rensinghof': 'f', 'Wil van der Aalst': 'g', 'Christine Dobbert': 'h', 'Luis Santos': 'i', 'Kefang Ding': 'j', 'Mohammadreza Fani Sani': 'k', 'Tobias Brockhoff': 'l', 'Anahita Farhang Ghahfarokhi': 'm', 'Mahnaz Qafari': 'n', 'Claudia Graf': 'o', 'Mahsa Bafrani': 'p', 'Lisa Mannel': 'q'}\n"
     ]
    }
   ],
   "source": [
    "from functions import preprossesing as prep\n",
    "from functions import folding\n",
    "import copy\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers.core import Dense\n",
    "from tensorflow.python.keras.layers import LSTM, Input\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "filename = \"running-example\"\n",
    "ocel, act_dict, cust_dict = prep.prepare_ocel(filename)\n",
    "print(act_dict)\n",
    "print(cust_dict)\n",
    "drops_col_order = [\"weight\", \"price\", \"Event_ID\", 'Products']\n",
    "\n",
    "ocel_orders = prep.flatten(ocel, 'Orders')\n",
    "enriched_log, single_log = prep.gen_enriched_single_plus_csv(OCEL = ocel_orders,flatted_by = 'Orders',csvname = 'orders_complete', drops_col= drops_col_order)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages\n",
      "          2000\n",
      "660001       5\n",
      "660002       2\n",
      "660003       4\n",
      "660004       4\n",
      "          ... \n",
      "661321       1\n",
      "661322       1\n",
      "661323       1\n",
      "661324       1\n",
      "661325       1\n",
      "Name: Orders, Length: 1326, dtype: int64\n",
      "Customers\n",
      "a    110\n",
      "b    120\n",
      "c    109\n",
      "d    125\n",
      "e    123\n",
      "f    113\n",
      "g    123\n",
      "h    132\n",
      "i    122\n",
      "j    125\n",
      "k    112\n",
      "l    100\n",
      "m    103\n",
      "n    122\n",
      "o    102\n",
      "p    127\n",
      "q    132\n",
      "Name: Orders, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filtered_index = ocel_orders.groupby('Packages')['Orders'] \\\n",
    "                            .apply(lambda x: len(x.unique())) \\\n",
    "                            #.loc[lambda x: x > 1].index\n",
    "print(filtered_index)\n",
    "## they are to many of them for one hot encodetbut i can use a flag if order is delvert with other orders in a package\n",
    "filtered_index = ocel_orders.groupby('Customers')['Orders'] \\\n",
    "                            .apply(lambda x: len(x.unique())) \\\n",
    "                            #.loc[lambda x: x > 1].index\n",
    "print(filtered_index)\n",
    "## this seems a good columns to one hot encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 103436.38622985176\n",
      "divisor2: 604261.1036767652\n",
      "divisorTR: 1248093.355995932\n",
      "numoof lines 2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "Ptimeseqs = []\n",
    "Ptimeseqs2 = []\n",
    "Ptimeseqs3 = []\n",
    "Ptimeseqs4 = []\n",
    "nb_itemseqs = []\n",
    "\n",
    "Ptimes = []\n",
    "Ptimes2 = []\n",
    "Ptimes3 = []\n",
    "Ptimes4 = []\n",
    "nb_items = []\n",
    "ascii_offset = 64\n",
    "Pcasestarttime = None\n",
    "Plasteventtime = None\n",
    "\n",
    "for index, row in enriched_log.iterrows():\n",
    "    t = row['Timestamp']\n",
    "    nb = row['Amount_Items']\n",
    "    if row['Case_ID'] != lastcase:\n",
    "        Stime = t\n",
    "        Pcasestarttime = t\n",
    "        Plasteventtime = t\n",
    "        lastcase = row['Case_ID']\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            Ptimeseqs.append(Ptimes)\n",
    "            Ptimeseqs2.append(Ptimes2)\n",
    "            Ptimeseqs3.append(Ptimes3)\n",
    "            Ptimeseqs4.append(Ptimes4)\n",
    "            nb_itemseqs.append(nb_items)\n",
    "\n",
    "        line = ''\n",
    "        Ptimes = []\n",
    "        Ptimes2 = []\n",
    "        Ptimes3 = []\n",
    "        Ptimes4 = []\n",
    "        nb_items = []\n",
    "\n",
    "    line += row['Activity'] #unichr(int(row['Activity']) + ascii_offset)\n",
    "    Ptimesincelastevent = t - Plasteventtime\n",
    "    Ptimesincecasestart = t - Pcasestarttime\n",
    "    midnight = t.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = t - midnight\n",
    "    Ptimediff = 86400 * Ptimesincelastevent.days + Ptimesincelastevent.seconds\n",
    "    Ptimediff2 = 86400 * Ptimesincecasestart.days + Ptimesincecasestart.seconds\n",
    "    Ptimediff3 = timesincemidnight.seconds\n",
    "    Ptimediff4 = t.weekday()\n",
    "    Ptimes.append(Ptimediff)\n",
    "    Ptimes2.append(Ptimediff2)\n",
    "    Ptimes3.append(Ptimediff3)\n",
    "    Ptimes4.append(Ptimediff4)\n",
    "    nb_items.append(nb)\n",
    "    Plasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# Add last case\n",
    "lines.append(line)\n",
    "Ptimeseqs.append(Ptimes)\n",
    "Ptimeseqs2.append(Ptimes2)\n",
    "Ptimeseqs3.append(Ptimes3)\n",
    "Ptimeseqs4.append(Ptimes4)\n",
    "nb_itemseqs.append(nb_items)\n",
    "\n",
    "PtimeseqsF = []\n",
    "for seq in Ptimeseqs2:\n",
    "    PtimeseqsF.append([seq[-1] - t for t in seq])\n",
    "\n",
    "\n",
    "\n",
    "divisor = np.mean([item for sublist in Ptimeseqs for item in sublist])  # average time between events\n",
    "divisor2 = np.mean([item for sublist in Ptimeseqs2 for item in sublist])  # average time between current and first events\n",
    "divisorTR = np.mean([item for sublist in PtimeseqsF for item in sublist])  # average time instance remaining\n",
    "print(f\"divisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "print(f'numoof lines {len(lines)}')\n",
    "print(len(nb_itemseqs))\n",
    "### folding the lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity sequences match 'lines' column: 0 mismatch(es).\n",
      "Ptimeseqs match 'Time_Diff' column: 0 mismatch(es).\n",
      "Ptimeseqs2 match 'Time_Since_Start' column: 0 mismatch(es).\n",
      "Ptimeseqs3 match 'Time_Since_Midnight' column: 0 mismatch(es).\n",
      "Ptimeseqs4 match 'Weekday' column: 0 mismatch(es).\n",
      "nb_itemseqs match 'Amount_Items' column: 0 mismatch(es).\n",
      "PtimeseqsF match 'Remaining_Time' column: 0 mismatch(es).\n",
      "divisor: 103436.38622985176\n",
      "divisor2: 604261.1036767652\n",
      "divisorTR: 1248093.355995932\n",
      "divisor: 103436.38622985176\n",
      "divisor2: 604261.1036767652\n",
      "divisorTR: 1248093.355995932\n",
      "The fierrence betwen the divisors are:\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "numoof lines 2000\n"
     ]
    }
   ],
   "source": [
    "# replaces lines activity sequences \n",
    "activity_sequences = enriched_log.groupby('Case_ID')['Activity'].apply(lambda x: ''.join(x)).reset_index()\n",
    "# replaces Ptimeseqs (time difference between events) but care it is not grouped for the case_ID\n",
    "enriched_log['Time_Diff'] = enriched_log.groupby('Case_ID')['Timestamp'].diff().fillna(pd.Timedelta(seconds=0)).dt.total_seconds().astype(int)\n",
    "# replaces Ptimeseqs2 (times since the start of the case) but care it is not grouped for the case_ID\n",
    "enriched_log['Time_Since_Start'] = (enriched_log['Timestamp'] - enriched_log.groupby('Case_ID')['Timestamp'].transform('first')).dt.total_seconds().astype(int)\n",
    "# replaces Ptimeseqs3 (time since the midnight) but care it is not grouped for the case_ID\n",
    "enriched_log['Time_Since_Midnight'] = (enriched_log['Timestamp'] - enriched_log['Timestamp'].dt.normalize()).dt.total_seconds().astype(int)\n",
    "# replaces Ptimeseqs4 (just weekday) but care it is not grouped for the case_ID\n",
    "enriched_log['Weekday'] = enriched_log['Timestamp'].dt.weekday\n",
    "# Calculate the remaining time for each case but care it is not grouped for the case_ID\n",
    "enriched_log['Remaining_Time'] = enriched_log.groupby('Case_ID')['Time_Since_Start'].transform(lambda x: x.max() - x)\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "# Check if activity sequences match with 'lines' column\n",
    "activity_match = sum(activity_sequences['Activity'] != lines)\n",
    "print(f\"Activity sequences match 'lines' column: {activity_match} mismatch(es).\")\n",
    "\n",
    "# Check if Ptimeseqs match with 'Time_Diff' column\n",
    "time_diff_match = sum(list(chain(*Ptimeseqs)) != enriched_log['Time_Diff'])\n",
    "print(f\"Ptimeseqs match 'Time_Diff' column: {time_diff_match} mismatch(es).\")\n",
    "\n",
    "# Check if Ptimeseqs2 match with 'Time_Since_Start' column\n",
    "time_start_match = sum(list(chain(*Ptimeseqs2)) != enriched_log['Time_Since_Start'])\n",
    "print(f\"Ptimeseqs2 match 'Time_Since_Start' column: {time_start_match} mismatch(es).\")\n",
    "\n",
    "# Check if Ptimeseqs3 match with 'Time_Since_Midnight' column\n",
    "time_midnight_match = sum(list(chain(*Ptimeseqs3)) != enriched_log['Time_Since_Midnight'])\n",
    "print(f\"Ptimeseqs3 match 'Time_Since_Midnight' column: {time_midnight_match} mismatch(es).\")\n",
    "\n",
    "# Check if Ptimeseqs4 match with 'Weekday' column\n",
    "weekday_match = sum(list(chain(*Ptimeseqs4)) != enriched_log['Weekday'])\n",
    "print(f\"Ptimeseqs4 match 'Weekday' column: {weekday_match} mismatch(es).\")\n",
    "\n",
    "# Check if nb_itemseqs match with 'Amount_Items' column\n",
    "nb_items_match = sum(list(chain(*nb_itemseqs)) != enriched_log['Amount_Items'])\n",
    "print(f\"nb_itemseqs match 'Amount_Items' column: {nb_items_match} mismatch(es).\")\n",
    "\n",
    "# Check if Ptimeseqs4 match with 'Remaining_Time' column\n",
    "remaining_time_match = sum(list(chain(*PtimeseqsF)) != enriched_log['Remaining_Time'])\n",
    "print(f\"PtimeseqsF match 'Remaining_Time' column: {remaining_time_match} mismatch(es).\")\n",
    "\n",
    "T__divisor = np.mean([item for sublist in Ptimeseqs for item in sublist])  # average time between events\n",
    "T__divisor2 = np.mean([item for sublist in Ptimeseqs2 for item in sublist])  # average time between current and first events\n",
    "T__divisorTR = np.mean([item for sublist in PtimeseqsF for item in sublist])  # average time instance remaining\n",
    "print(f\"divisor: {T__divisor}\")\n",
    "print(f\"divisor2: {T__divisor2}\")\n",
    "print(f\"divisorTR: {T__divisorTR}\")\n",
    "\n",
    "divisor = np.mean(enriched_log['Time_Diff'])  # average time between events\n",
    "divisor2 = np.mean(enriched_log['Time_Since_Start'])  # average time between current and first events\n",
    "divisorTR = np.mean(enriched_log['Remaining_Time'])  # average time instance remaining\n",
    "print(f\"divisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "print('The difference between the divisors are:')\n",
    "print(T__divisor -divisor)\n",
    "print(T__divisor2 -divisor2)\n",
    "print(T__divisorTR -divisorTR)\n",
    "\n",
    "print(f'numoof lines {len(lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Items</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Packages</th>\n",
       "      <th>Amount_Items</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Time_Since_Start</th>\n",
       "      <th>Time_Since_Midnight</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Remaining_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>990001</td>\n",
       "      <td>A</td>\n",
       "      <td>2019-05-20 09:07:47</td>\n",
       "      <td>[880001, 880004, 880003, 880002]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32867</td>\n",
       "      <td>0</td>\n",
       "      <td>3197465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>990001</td>\n",
       "      <td>C</td>\n",
       "      <td>2019-05-20 11:13:54</td>\n",
       "      <td>[880001, 880004, 880003, 880002]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>7567</td>\n",
       "      <td>7567</td>\n",
       "      <td>40434</td>\n",
       "      <td>0</td>\n",
       "      <td>3189898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>990001</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-05-20 11:20:13</td>\n",
       "      <td>[880002]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>379</td>\n",
       "      <td>7946</td>\n",
       "      <td>40813</td>\n",
       "      <td>0</td>\n",
       "      <td>3189519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>990001</td>\n",
       "      <td>D</td>\n",
       "      <td>2019-05-20 13:54:37</td>\n",
       "      <td>[880004]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>9264</td>\n",
       "      <td>17210</td>\n",
       "      <td>50077</td>\n",
       "      <td>0</td>\n",
       "      <td>3180255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>990001</td>\n",
       "      <td>E</td>\n",
       "      <td>2019-05-21 10:03:49</td>\n",
       "      <td>[880004]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>72552</td>\n",
       "      <td>89762</td>\n",
       "      <td>36229</td>\n",
       "      <td>1</td>\n",
       "      <td>3107703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32075</th>\n",
       "      <td>992000</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-05-19 10:20:22</td>\n",
       "      <td>[888159]</td>\n",
       "      <td>q</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>70279</td>\n",
       "      <td>71336</td>\n",
       "      <td>37222</td>\n",
       "      <td>1</td>\n",
       "      <td>214226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32165</th>\n",
       "      <td>992000</td>\n",
       "      <td>G</td>\n",
       "      <td>2020-05-21 09:04:20</td>\n",
       "      <td>[888014, 888159, 888146, 888144, 888145]</td>\n",
       "      <td>q</td>\n",
       "      <td>661303</td>\n",
       "      <td>5</td>\n",
       "      <td>168238</td>\n",
       "      <td>239574</td>\n",
       "      <td>32660</td>\n",
       "      <td>3</td>\n",
       "      <td>45988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32190</th>\n",
       "      <td>992000</td>\n",
       "      <td>H</td>\n",
       "      <td>2020-05-21 15:27:54</td>\n",
       "      <td>[888014, 888159, 888146, 888144, 888145]</td>\n",
       "      <td>q</td>\n",
       "      <td>661303</td>\n",
       "      <td>5</td>\n",
       "      <td>23014</td>\n",
       "      <td>262588</td>\n",
       "      <td>55674</td>\n",
       "      <td>3</td>\n",
       "      <td>22974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32209</th>\n",
       "      <td>992000</td>\n",
       "      <td>J</td>\n",
       "      <td>2020-05-21 21:43:23</td>\n",
       "      <td>[888014, 888159, 888146, 888144, 888145]</td>\n",
       "      <td>q</td>\n",
       "      <td>661303</td>\n",
       "      <td>5</td>\n",
       "      <td>22529</td>\n",
       "      <td>285117</td>\n",
       "      <td>78203</td>\n",
       "      <td>3</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32211</th>\n",
       "      <td>992000</td>\n",
       "      <td>F</td>\n",
       "      <td>2020-05-21 21:50:48</td>\n",
       "      <td>[888159]</td>\n",
       "      <td>q</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>285562</td>\n",
       "      <td>78648</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32447 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case_ID Activity           Timestamp   \n",
       "0      990001        A 2019-05-20 09:07:47  \\\n",
       "3      990001        C 2019-05-20 11:13:54   \n",
       "4      990001        B 2019-05-20 11:20:13   \n",
       "7      990001        D 2019-05-20 13:54:37   \n",
       "25     990001        E 2019-05-21 10:03:49   \n",
       "...       ...      ...                 ...   \n",
       "32075  992000        B 2020-05-19 10:20:22   \n",
       "32165  992000        G 2020-05-21 09:04:20   \n",
       "32190  992000        H 2020-05-21 15:27:54   \n",
       "32209  992000        J 2020-05-21 21:43:23   \n",
       "32211  992000        F 2020-05-21 21:50:48   \n",
       "\n",
       "                                          Items Customers Packages   \n",
       "0              [880001, 880004, 880003, 880002]         a           \\\n",
       "3              [880001, 880004, 880003, 880002]         a            \n",
       "4                                      [880002]         a            \n",
       "7                                      [880004]         a            \n",
       "25                                     [880004]         a            \n",
       "...                                         ...       ...      ...   \n",
       "32075                                  [888159]         q            \n",
       "32165  [888014, 888159, 888146, 888144, 888145]         q   661303   \n",
       "32190  [888014, 888159, 888146, 888144, 888145]         q   661303   \n",
       "32209  [888014, 888159, 888146, 888144, 888145]         q   661303   \n",
       "32211                                  [888159]         q            \n",
       "\n",
       "       Amount_Items  Time_Diff  Time_Since_Start  Time_Since_Midnight   \n",
       "0                 4          0                 0                32867  \\\n",
       "3                 4       7567              7567                40434   \n",
       "4                 1        379              7946                40813   \n",
       "7                 1       9264             17210                50077   \n",
       "25                1      72552             89762                36229   \n",
       "...             ...        ...               ...                  ...   \n",
       "32075             1      70279             71336                37222   \n",
       "32165             5     168238            239574                32660   \n",
       "32190             5      23014            262588                55674   \n",
       "32209             5      22529            285117                78203   \n",
       "32211             1        445            285562                78648   \n",
       "\n",
       "       Weekday  Remaining_Time  \n",
       "0            0         3197465  \n",
       "3            0         3189898  \n",
       "4            0         3189519  \n",
       "7            0         3180255  \n",
       "25           1         3107703  \n",
       "...        ...             ...  \n",
       "32075        1          214226  \n",
       "32165        3           45988  \n",
       "32190        3           22974  \n",
       "32209        3             445  \n",
       "32211        3               0  \n",
       "\n",
       "[32447 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines, lines_t, lines_t2, lines_t3, lines_t4, lines_t5, lines_t6 = folding.folding_this(lines,Ptimeseqs,Ptimeseqs2,Ptimeseqs3,Ptimeseqs4,nb_itemseqs,PtimeseqsF,seeded = 42)\n",
    "\n",
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x + '!', lines))  # put delimiter symbol\n",
    "maxlen = max(map(lambda x: len(x), lines))  # find maximum line size\n",
    "\n",
    "# next lines here to get all possible characters for events and annotate them with numbers\n",
    "# chars = map(lambda x: set(x),lines)\n",
    "chars = list(set().union(*map(lambda x: set(x), lines)))\n",
    "chars.sort()\n",
    "target_chars = copy.copy(chars)\n",
    "chars.remove('!')\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "target_char_indices = dict((c, i) for i, c in enumerate(target_chars))\n",
    "target_indices_char = dict((i, c) for i, c in enumerate(target_chars))\n",
    "print(indices_char)\n",
    "\n",
    "sentences_t = []\n",
    "sentences_t2 = []\n",
    "sentences_t3 = []\n",
    "sentences_t4 = []\n",
    "sentences_t5 = []\n",
    "sentences_t6 = []\n",
    "\n",
    "\n",
    "next_chars_t = []\n",
    "next_chars_t2 = []\n",
    "next_chars_t3 = []\n",
    "next_chars_t4 = []\n",
    "next_chars_t5 = []\n",
    "next_chars_t6 = []\n",
    "\n",
    "\n",
    "for line, line_t, line_t2, line_t3, line_t4, line_t5, line_t6 in zip(lines, lines_t, lines_t2, lines_t3, lines_t4, lines_t5, lines_t6):\n",
    "    for i in range(0, len(line), step):\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        # we add iteratively, first symbol of the line, then two first, three...\n",
    "\n",
    "        sentences.append(line[0: i])\n",
    "        sentences_t.append(line_t[0:i])\n",
    "        sentences_t2.append(line_t2[0:i])\n",
    "        sentences_t3.append(line_t3[0:i])\n",
    "        sentences_t4.append(line_t4[0:i])\n",
    "        sentences_t5.append(line_t5[0:i])\n",
    "        sentences_t6.append(line_t6[0:i])\n",
    "        next_chars.append(line[i])\n",
    "        if i == len(line) - 1:  # special case to deal time of end character\n",
    "            next_chars_t.append(0)\n",
    "            next_chars_t2.append(0)\n",
    "            next_chars_t3.append(0)\n",
    "            next_chars_t4.append(0)\n",
    "            next_chars_t5.append(0)\n",
    "            next_chars_t6.append(0)\n",
    "\n",
    "\n",
    "        else:\n",
    "            next_chars_t.append(line_t[i])\n",
    "            next_chars_t2.append(line_t2[i])\n",
    "            next_chars_t3.append(line_t3[i])\n",
    "            next_chars_t4.append(line_t4[i])\n",
    "            next_chars_t5.append(line_t5[i])\n",
    "            next_chars_t6.append(line_t6[i])\n",
    "\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "num_features = len(chars) + 6\n",
    "print('num features: {}'.format(num_features))\n",
    "X = np.zeros((len(sentences), maxlen, num_features), dtype=np.float32)\n",
    "y_a = np.zeros((len(sentences), len(target_chars)), dtype=np.float32)\n",
    "y_t = np.zeros((len(sentences)), dtype=np.float32)\n",
    "y_tr = np.zeros((len(sentences)), dtype=np.float32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    leftpad = maxlen - len(sentence)\n",
    "    next_t = next_chars_t[i]\n",
    "    next_tr = next_chars_t6[i] # wrong in original code was t5\n",
    "\n",
    "    sentence_t = sentences_t[i]\n",
    "    sentence_t2 = sentences_t2[i]\n",
    "    sentence_t3 = sentences_t3[i]\n",
    "    sentence_t4 = sentences_t4[i]\n",
    "    sentence_t5 = sentences_t5[i]\n",
    "\n",
    "    for t, char in enumerate(sentence):\n",
    "        for c in chars:\n",
    "            if c == char:  # this will encode present events to the right places\n",
    "                X[i, t + leftpad, char_indices[c]] = 1\n",
    "        X[i, t + leftpad, len(chars)] = t + 1\n",
    "        X[i, t + leftpad, len(chars) + 1] = sentence_t[t] / divisor\n",
    "        X[i, t + leftpad, len(chars) + 2] = sentence_t2[t] / divisor2\n",
    "        X[i, t + leftpad, len(chars) + 3] = sentence_t3[t] / 86400\n",
    "        X[i, t + leftpad, len(chars) + 4] = sentence_t4[t] / 7\n",
    "\n",
    "    for c in target_chars:\n",
    "        if c == next_chars[i]:\n",
    "            y_a[i, target_char_indices[c]] = 1 - softness\n",
    "        else:\n",
    "            y_a[i, target_char_indices[c]] = softness / (len(target_chars) - 1)\n",
    "    y_t[i] = next_t / divisor\n",
    "    y_tr[i] = next_tr / divisorTR\n",
    "\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y_a: {y_a.shape}\")\n",
    "print(f\"Shape of y_t: {y_t.shape}\")\n",
    "print(f\"Shape of y_tr: {y_tr.shape}\")\n",
    "# Reshape the 3D array into 2D\n",
    "reshaped_data = X.reshape((-1, X.shape[-1]))\n",
    "\n",
    "# Convert reshaped ndarray to DataFrame\n",
    "df = pd.DataFrame(reshaped_data)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "display(df[77:85])#.drop_duplicates())\n",
    "display(df[40:42])#.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')\n",
    "# train a 2-layer LSTM with one shared layer\n",
    "l1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(\n",
    "    main_input)  # the shared layer\n",
    "b1 = tf.keras.layers.BatchNormalization()(l1)\n",
    "l2_1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(\n",
    "    b1)  # the layer specialized in activity prediction\n",
    "b2_1 = tf.keras.layers.BatchNormalization()(l2_1)\n",
    "l2_2 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(\n",
    "    b1)  # the layer specialized in time prediction\n",
    "b2_2 = tf.keras.layers.BatchNormalization()(l2_2)\n",
    "l2_3 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(\n",
    "    b1)  # the layer specialized in time remaining prediction\n",
    "b2_3 = tf.keras.layers.BatchNormalization()(l2_3)\n",
    "act_output = Dense(len(target_chars), activation='softmax', kernel_initializer='glorot_uniform', name='act_output')(\n",
    "    b2_1)\n",
    "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(b2_2)\n",
    "\n",
    "timeR_output = Dense(1, kernel_initializer='glorot_uniform', name='timeR_output')(b2_3)\n",
    "\n",
    "model = Model(inputs=[main_input], outputs=[act_output, time_output, timeR_output])\n",
    "\n",
    "model.compile(loss={'act_output': 'categorical_crossentropy', 'time_output': 'mae', 'timeR_output': 'mae'}, optimizer='nadam')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "model_checkpoint = ModelCheckpoint('./output_files/models/model_'+filename+'_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss',\n",
    "                                   verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, verbose=0, mode='auto', min_delta=0.0001,\n",
    "                               cooldown=0, min_lr=0)\n",
    "\n",
    "history = model.fit(X, {'act_output': y_a, 'time_output': y_t, 'timeR_output': y_tr}, validation_split=0.2, verbose=2,\n",
    "          callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, epochs=500)\n",
    "# list all data in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# # summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
