{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import (prep, folding, inbu, LSTM_model)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(42)\n",
    "source = \"running-example\"\n",
    "flatten_by = 'Orders' # input(\"Enter the value for flatten_by (Orders, Items or Packages): \")\n",
    "single_log = 'False' # input(\"Enter the value for single_log (True/False): \")\n",
    "complete = 'False' # input(\"Enter the value for complete (True/False): \")\n",
    "testing_other_remaining = False\n",
    "add_customer = 0\n",
    "\n",
    "# Error handling for invalid input values\n",
    "if flatten_by not in ['Orders', 'Items', 'Packages']:\n",
    "    raise ValueError(\"Wrong Input: flatten_by must be one of ['Orders', 'Items', 'Packages']\")\n",
    "\n",
    "if single_log.lower() not in ['true', 'false', '1', '0']:\n",
    "    raise ValueError(\"Wrong Input: single_log must be a boolean value (True/False)\")\n",
    "\n",
    "if complete.lower() not in ['true', 'false', '1', '0']:\n",
    "    raise ValueError(\"Wrong Input: complete must be a boolean value (True/False)\")\n",
    "\n",
    "# Convert input values to boolean\n",
    "single_log = single_log.lower() in ['true', '1']\n",
    "complete = complete.lower() in ['true', '1'] \n",
    "if complete:\n",
    "    csvname = flatten_by  + '_complete'\n",
    "    fl = None\n",
    "else:\n",
    "    csvname = flatten_by  + '_filter'\n",
    "    fl = prep.act_filter(flatten_by )\n",
    "\n",
    "time_feat = ['Time_Diff', 'Time_Since_Start', 'Time_Since_Midnight','Weekday','Position']\n",
    "other_features = ['Amount_Items','In_Package']\n",
    "drops_col_order = [\"weight\", \"price\", \"Event_ID\", 'Products']\n",
    "print(\"Settings:\")\n",
    "print(f\"flatten_by: {flatten_by}\")\n",
    "print(f\"single_log: {single_log}\")\n",
    "print(f\"complete: {complete}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prep the ocel and readin\n",
    "ocel, act_dict, cust_dict = prep.prepare_flat_ocel(source, flatten_on= flatten_by , filter= fl)\n",
    "print(act_dict)\n",
    "print(cust_dict)\n",
    "## create the enriched and some more preprocessing as well as saving the single and enriched versions\n",
    "ocel = prep.gen_enriched_single_plus_csv(OCEL = ocel,flatted_by = flatten_by ,csvname = csvname, drops_col= drops_col_order)\n",
    "## adding features\n",
    "ocel =prep.generate_features(ocel)\n",
    "divisor = np.mean(ocel['Time_Diff'])  # average time between events\n",
    "divisor2 = np.mean(ocel['Time_Since_Start'])  # average time between current and first events\n",
    "divisorTR = np.mean(ocel['Remaining_Time'])  # average time instance remaining\n",
    "divisor3 = ocel.groupby('Case_ID')['Time_Since_Start'].apply(lambda x: (x.iloc[-1] - x).mean()).mean()\n",
    "\n",
    "print(f\"divisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "print(f\"divisor3: {divisor3}\")\n",
    "print(len(ocel))\n",
    "\n",
    "#folding the data \n",
    "ocel_train, ocel_test = folding.folding_train_test(ocel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features *(1-int(single_log))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "act_feat = list(filter(lambda k: k.startswith('Act_') and not k.startswith('Next_Act_'), ocel_train.columns))\n",
    "act_feat.remove('Act_!')\n",
    "act_feat_dict = {index: value.replace('Act_', '') for index, value in enumerate(act_feat)}\n",
    "target_act_feat = list(filter(lambda k: k.startswith('Next_Act_') and not k.startswith('Act_'), ocel_train.columns))\n",
    "target_act_feat_dict = {index: value.replace('Next_Act_', '') for index, value in enumerate(target_act_feat)}\n",
    "\n",
    "cust_feat = list(filter(lambda k: 'Cust_' in k, ocel_train.columns)) * (1 - int(single_log)) * add_customer\n",
    "\n",
    "feature_select = act_feat + cust_feat + time_feat + other_features *(1 - int(single_log))\n",
    "print(f\"Length of act_feat: {len(act_feat)}, Length of cust_feat: {len(cust_feat)}\")\n",
    "\n",
    "## define dimensions of inputs\n",
    "max_trace_length = prep.gen_traces_and_maxlength_of_trace(ocel)[1]\n",
    "target_act_length = len(target_act_feat)\n",
    "number_of_train_cases = len(ocel_train)\n",
    "num_of_features = len(feature_select)\n",
    "print(f\"Number of train cases: {number_of_train_cases}, Max trace length: {max_trace_length}, Number of features: {num_of_features}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_act_feat_dict)\n",
    "print(act_feat_dict)\n",
    "print(num_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train_a, y_train_t, y_train_tr = inbu.generating_inputs(OCEL=ocel_train,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR, \n",
    "                                                                  single= single_log,\n",
    "                                                                  test = testing_other_remaining)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): {(number_of_train_cases, max_trace_length, num_of_features)} => {X_train.shape ==(number_of_train_cases, max_trace_length, num_of_features)}\")\n",
    "print(f\"Shape of y_train_a: {y_train_a.shape}, this matches the desired shape (number_of_train_cases, target_act_length): {(number_of_train_cases, target_act_length)} => {y_train_a.shape ==(number_of_train_cases, target_act_length)}\")\n",
    "print(f\"Shape of y_train_t: {y_train_t.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_t.shape ==(number_of_train_cases, )}\")\n",
    "print(f\"Shape of y_train_tr: {y_train_tr.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_tr.shape ==(number_of_train_cases, )}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if single_log:\n",
    "    model_file = csvname + '_single'\n",
    "else:\n",
    "    model_file = csvname + '_enriched'\n",
    "history, best_model_name= LSTM_model.LSTM_MODEL(X_train, y_train_a, y_train_t, y_train_tr,filename=model_file)\n",
    "# print(history.history.keys())\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(best_model_name.best)\n",
    "os.path.basename(best_model_name.filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from jellyfish import damerau_levenshtein_distance, levenshtein_distance\n",
    "import pandas as pd\n",
    "import distance\n",
    "\n",
    "modelname = os.path.basename(best_model_name.filepath)\n",
    "model = load_model(f'./output_files/models/{modelname}')\n",
    "\n",
    "X_test,y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(OCEL=ocel_test,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR, \n",
    "                                                                  single= single_log,\n",
    "                                                                  test = testing_other_remaining)\n",
    "\n",
    "# y_t = y_t * divisor3\n",
    "\n",
    "y = model.predict(X_test,verbose=1)\n",
    "y_char = y[0][:][:]\n",
    "y_t = y[1][:][:]\n",
    "y_tr = y[2][:][:]\n",
    "max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "y_t = np.maximum(y_t, 0)\n",
    "y_t1 = y_t * divisor\n",
    "y_tr1 = y_tr * divisorTR\n",
    "\n",
    "columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                  [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                  ['Items', 'Customers', 'Packages', 'Next_Time_Since_Start',\n",
    "                   'Next_Time_Since_Midnight', 'Next_Weekday', 'In_Package',\n",
    "                   'Position', 'Time_Since_Midnight', 'Weekday', 'Amount_Items']\n",
    "\n",
    "output_ocel = ocel_test.drop(columns=columns_to_drop).copy()\n",
    "output_ocel['Pred_Activity'] = pred_act_list\n",
    "output_ocel['Pred_Time_Diff'] = y_t1\n",
    "output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "output_ocel\n",
    "from sklearn import metrics\n",
    "act_comp = output_ocel['Pred_Activity'] == output_ocel['Next_Activity'] \n",
    "print(sum(act_comp)/len(act_comp))\n",
    "print(metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60)))\n",
    "print(metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60)))\n",
    "print(metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60),squared=False))\n",
    "print(metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60),squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.604857336903863\n",
    "3.197816839635765\n",
    "4.759801071662072\n",
    "8.059703481044945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import damerau_levenshtein_distance, levenshtein_distance\n",
    "import pandas as pd\n",
    "import distance\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate inputs with varying prefix lengths\n",
    "prefix_lengths = range(2, max_trace_length-1)  # List of prefix lengths to consider\n",
    "results = []\n",
    "\n",
    "for prefix_length in prefix_lengths:\n",
    "    print(f\"Results for Prefix Length {prefix_length}:\")\n",
    "    \n",
    "    # Generate inputs with the current prefix length\n",
    "    X_test, y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(OCEL=ocel_test,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR,\n",
    "                                                                  single=single_log,\n",
    "                                                                  prefix_length=prefix_length,\n",
    "                                                                  test = testing_other_remaining)\n",
    "\n",
    "    # Make predictions with the model\n",
    "    y = model.predict(X_test, verbose=1)\n",
    "    y_char = y[0][:][:]\n",
    "    y_t = y[1][:][:]\n",
    "    y_tr = y[2][:][:]\n",
    "\n",
    "    max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "    pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "    y_t = np.maximum(y_t, 0)\n",
    "    y_t1 = y_t * divisor\n",
    "    y_tr1 = y_tr * divisorTR\n",
    "\n",
    "    columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                      [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                      ['Items', 'Customers', 'Packages', 'Next_Time_Since_Start',\n",
    "                       'Next_Time_Since_Midnight', 'Next_Weekday', 'In_Package',\n",
    "                       'Position', 'Time_Since_Midnight', 'Weekday', 'Amount_Items']\n",
    "    trace_length = ocel_test['Trace_Len'].values\n",
    "    output_ocel = ocel_test[trace_length >= prefix_length].reset_index(drop= True).drop(columns=columns_to_drop).copy()\n",
    "    output_ocel['Pred_Activity'] = pred_act_list\n",
    "    output_ocel['Pred_Time_Diff'] = y_t1\n",
    "    output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "    output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "    output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "    mae_time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60)) \n",
    "    mae_remaining_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60)) \n",
    "    rmse_time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60), squared=False) \n",
    "    rmse_remaining_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60), squared=False) \n",
    "\n",
    "    # Store the results for the current prefix length\n",
    "    results.append({\n",
    "        'Prefix Length': prefix_length,\n",
    "        'length': len(y_tr),\n",
    "        'MAE Time Difference': mae_time_diff,\n",
    "        'MAE Remaining Time': mae_remaining_time,\n",
    "        'RMSE Time Difference': rmse_time_diff,\n",
    "        'RMSE Remaining Time': rmse_remaining_time\n",
    "    })\n",
    "\n",
    "    # Output additional values based on Case_ID and prefix length\n",
    "    for case_id in output_ocel['Case_ID'].unique():\n",
    "        case_data = output_ocel[output_ocel['Case_ID'] == case_id]\n",
    "        trace_length = len(case_data)\n",
    "        if prefix_length <= trace_length:\n",
    "            # print(f\"\\nAdditional values for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            case_data_prefix = case_data[:prefix_length]\n",
    "            #print(case_data_prefix.to_string(index=False))\n",
    "            \n",
    "            mae_time_diff_case = metrics.mean_absolute_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "            mae_remaining_time_case = metrics.mean_absolute_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "            rmse_time_diff_case = metrics.mean_squared_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60), squared=False)\n",
    "            rmse_remaining_time_case = metrics.mean_squared_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60), squared=False)\n",
    "            \n",
    "            # print(f\"\\nMetrics for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            # print(\"MAE Time Difference:\", mae_time_diff_case)\n",
    "            # print(\"MAE Remaining Time:\", mae_remaining_time_case)\n",
    "            # print(\"RMSE Time Difference:\", rmse_time_diff_case)\n",
    "            # print(\"RMSE Remaining Time:\", rmse_remaining_time_case)\n",
    "\n",
    "# Output the overall results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Results:\n",
    "   Prefix Length  length  MAE Time Difference  MAE Remaining Time   \n",
    "0              2    2148             2.618387            3.210506  \\\n",
    "1              3    2148             2.610200            3.178392   \n",
    "2              4     510             5.189373            8.829667   \n",
    "3              5     126             6.830172           16.141236   \n",
    "4              6      31             7.683536           24.763984   \n",
    "5              7       7             8.797930           35.491213   \n",
    "\n",
    "   RMSE Time Difference  RMSE Remaining Time  \n",
    "0              4.798312             8.495652  \n",
    "1              4.756645             8.264313  \n",
    "2              7.870040            15.821624  \n",
    "3              9.429331            25.044045  \n",
    "4             10.219038            35.647287  \n",
    "5             11.258677            47.561489 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
