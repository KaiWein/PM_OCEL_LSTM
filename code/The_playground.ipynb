{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "flatten_by: Orders\n",
      "single_log: True\n",
      "complete: False\n"
     ]
    }
   ],
   "source": [
    "from functions import (prep, folding, inbu, LSTM_model)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(42)\n",
    "source = \"running-example\"\n",
    "flatten_by = 'Orders' # input(\"Enter the value for flatten_by (Orders, Items or Packages): \")\n",
    "single_log = 'True' # input(\"Enter the value for single_log (True/False): \")\n",
    "complete = 'False' # input(\"Enter the value for complete (True/False): \")\n",
    "\n",
    "# Error handling for invalid input values\n",
    "if flatten_by not in ['Orders', 'Items', 'Packages']:\n",
    "    raise ValueError(\"Wrong Input: flatten_by must be one of ['Orders', 'Items', 'Packages']\")\n",
    "\n",
    "if single_log.lower() not in ['true', 'false', '1', '0']:\n",
    "    raise ValueError(\"Wrong Input: single_log must be a boolean value (True/False)\")\n",
    "\n",
    "if complete.lower() not in ['true', 'false', '1', '0']:\n",
    "    raise ValueError(\"Wrong Input: complete must be a boolean value (True/False)\")\n",
    "\n",
    "# Convert input values to boolean\n",
    "single_log = single_log.lower() in ['true', '1']\n",
    "complete = complete.lower() in ['true', '1'] \n",
    "if complete:\n",
    "    csvname = flatten_by  + '_complete'\n",
    "    fl = None\n",
    "else:\n",
    "    csvname = flatten_by  + '_filter'\n",
    "    fl = prep.act_filter(flatten_by )\n",
    "\n",
    "time_feat = ['Time_Diff', 'Time_Since_Start', 'Time_Since_Midnight','Weekday','Position']\n",
    "other_features = ['Amount_Items','In_Package']\n",
    "drops_col_order = [\"weight\", \"price\", \"Event_ID\", 'Products']\n",
    "print(\"Settings:\")\n",
    "print(f\"flatten_by: {flatten_by}\")\n",
    "print(f\"single_log: {single_log}\")\n",
    "print(f\"complete: {complete}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place order': 'A', 'confirm order': 'B', 'pay order': 'C', 'payment reminder': 'D'}\n",
      "{'Marco Pegoraro': 'a', 'Gyunam Park': 'b', 'Majid Rafiei': 'c', 'Junxiong Gao': 'd', 'Seran Uysal': 'e', 'Christina Rensinghof': 'f', 'Wil van der Aalst': 'g', 'Christine Dobbert': 'h', 'Luis Santos': 'i', 'Kefang Ding': 'j', 'Mohammadreza Fani Sani': 'k', 'Tobias Brockhoff': 'l', 'Anahita Farhang Ghahfarokhi': 'm', 'Mahnaz Qafari': 'n', 'Claudia Graf': 'o', 'Mahsa Bafrani': 'p', 'Lisa Mannel': 'q'}\n",
      "divisor: 318986.03791832976\n",
      "divisor2: 528541.2252072459\n",
      "divisorTR: 679045.650752226\n",
      "divisor3: 591967.807807143\n",
      "6514\n"
     ]
    }
   ],
   "source": [
    "## prep the ocel and readin\n",
    "ocel, act_dict, cust_dict = prep.prepare_flat_ocel(source, flatten_on= flatten_by , filter= fl)\n",
    "print(act_dict)\n",
    "print(cust_dict)\n",
    "## create the enriched and some more preprocessing as well as saving the single and enriched versions\n",
    "ocel = prep.gen_enriched_single_plus_csv(OCEL = ocel,flatted_by = flatten_by ,csvname = csvname, drops_col= drops_col_order)\n",
    "## adding features\n",
    "ocel =prep.generate_features(ocel)\n",
    "divisor = np.mean(ocel['Time_Diff'])  # average time between events\n",
    "divisor2 = np.mean(ocel['Time_Since_Start'])  # average time between current and first events\n",
    "divisorTR = np.mean(ocel['Remaining_Time'])  # average time instance remaining\n",
    "divisor3 = ocel.groupby('Case_ID')['Time_Since_Start'].apply(lambda x: (x.iloc[-1] - x).mean()).mean()\n",
    "\n",
    "print(f\"divisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "print(f\"divisor3: {divisor3}\")\n",
    "print(len(ocel))\n",
    "\n",
    "#folding the data \n",
    "ocel_train, ocel_test = folding.folding_train_test(ocel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of act_feat: 4, Length of cust_feat: 18\n",
      "Number of train cases: 4366, Max trace length: 9, Number of features: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "act_feat = list(filter(lambda k: k.startswith('Act_') and not k.startswith('Next_Act_'), ocel_train.columns))\n",
    "act_feat.remove('Act_!')\n",
    "act_feat_dict = {index: value.replace('Act_', '') for index, value in enumerate(act_feat)}\n",
    "target_act_feat = list(filter(lambda k: k.startswith('Next_Act_') and not k.startswith('Act_'), ocel_train.columns))\n",
    "target_act_feat_dict = {index: value.replace('Next_Act_', '') for index, value in enumerate(target_act_feat)}\n",
    "\n",
    "cust_feat = list(filter(lambda k: 'Cust_' in k, ocel_train.columns))\n",
    "\n",
    "feature_select = act_feat + cust_feat * (single_log -1) + time_feat + other_features *(single_log -1)\n",
    "print(f\"Length of act_feat: {len(act_feat)}, Length of cust_feat: {len(cust_feat)}\")\n",
    "\n",
    "## define dimensions of inputs\n",
    "max_trace_length = prep.gen_traces_and_maxlength_of_trace(ocel)[1]\n",
    "target_act_length = len(target_act_feat)\n",
    "number_of_train_cases = len(ocel_train)\n",
    "num_of_features = len(feature_select)\n",
    "print(f\"Number of train cases: {number_of_train_cases}, Max trace length: {max_trace_length}, Number of features: {num_of_features}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '!', 1: 'A', 2: 'B', 3: 'C', 4: 'D'}\n",
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n"
     ]
    }
   ],
   "source": [
    "print(target_act_feat_dict)\n",
    "print(act_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Items</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Packages</th>\n",
       "      <th>Amount_Items</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Time_Since_Start</th>\n",
       "      <th>Time_Since_Midnight</th>\n",
       "      <th>...</th>\n",
       "      <th>Cust_o</th>\n",
       "      <th>Cust_p</th>\n",
       "      <th>Cust_q</th>\n",
       "      <th>Next_Activity</th>\n",
       "      <th>Next_Act_!</th>\n",
       "      <th>Next_Act_A</th>\n",
       "      <th>Next_Act_B</th>\n",
       "      <th>Next_Act_C</th>\n",
       "      <th>Next_Act_D</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>990001</td>\n",
       "      <td>A</td>\n",
       "      <td>2019-05-20 09:07:47</td>\n",
       "      <td>[880001, 880004, 880003, 880002]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32867</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>990001</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-05-20 11:13:54</td>\n",
       "      <td>[880001, 880004, 880003, 880002]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>7567</td>\n",
       "      <td>7567</td>\n",
       "      <td>40434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990001</td>\n",
       "      <td>C</td>\n",
       "      <td>2019-05-23 11:27:55</td>\n",
       "      <td>[880001, 880004, 880003, 880002]</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>260041</td>\n",
       "      <td>267608</td>\n",
       "      <td>41275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>990002</td>\n",
       "      <td>A</td>\n",
       "      <td>2019-05-20 10:35:21</td>\n",
       "      <td>[880008, 880005, 880006, 880007]</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>990002</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-05-21 12:19:16</td>\n",
       "      <td>[880008, 880005, 880006, 880007]</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>92635</td>\n",
       "      <td>92635</td>\n",
       "      <td>44356</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>991999</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-05-18 16:55:39</td>\n",
       "      <td>[888154, 888157, 888155, 888158, 888156]</td>\n",
       "      <td>o</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>15590</td>\n",
       "      <td>15590</td>\n",
       "      <td>60939</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>991999</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-05-29 17:20:28</td>\n",
       "      <td>[888154, 888157, 888155, 888158, 888156]</td>\n",
       "      <td>o</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>951889</td>\n",
       "      <td>967479</td>\n",
       "      <td>62428</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>992000</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-05-18 14:31:26</td>\n",
       "      <td>[888159]</td>\n",
       "      <td>q</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52286</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>992000</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-05-18 14:49:03</td>\n",
       "      <td>[888159]</td>\n",
       "      <td>q</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>53343</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6513</th>\n",
       "      <td>992000</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-05-21 21:50:48</td>\n",
       "      <td>[888159]</td>\n",
       "      <td>q</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>284505</td>\n",
       "      <td>285562</td>\n",
       "      <td>78648</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6514 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case_ID Activity           Timestamp   \n",
       "0     990001        A 2019-05-20 09:07:47  \\\n",
       "1     990001        B 2019-05-20 11:13:54   \n",
       "2     990001        C 2019-05-23 11:27:55   \n",
       "3     990002        A 2019-05-20 10:35:21   \n",
       "4     990002        B 2019-05-21 12:19:16   \n",
       "...      ...      ...                 ...   \n",
       "6509  991999        B 2020-05-18 16:55:39   \n",
       "6510  991999        C 2020-05-29 17:20:28   \n",
       "6511  992000        A 2020-05-18 14:31:26   \n",
       "6512  992000        B 2020-05-18 14:49:03   \n",
       "6513  992000        C 2020-05-21 21:50:48   \n",
       "\n",
       "                                         Items Customers Packages   \n",
       "0             [880001, 880004, 880003, 880002]         a           \\\n",
       "1             [880001, 880004, 880003, 880002]         a            \n",
       "2             [880001, 880004, 880003, 880002]         a            \n",
       "3             [880008, 880005, 880006, 880007]         b            \n",
       "4             [880008, 880005, 880006, 880007]         b            \n",
       "...                                        ...       ...      ...   \n",
       "6509  [888154, 888157, 888155, 888158, 888156]         o            \n",
       "6510  [888154, 888157, 888155, 888158, 888156]         o            \n",
       "6511                                  [888159]         q            \n",
       "6512                                  [888159]         q            \n",
       "6513                                  [888159]         q            \n",
       "\n",
       "      Amount_Items  Time_Diff  Time_Since_Start  Time_Since_Midnight  ...   \n",
       "0                4          0                 0                32867  ...  \\\n",
       "1                4       7567              7567                40434  ...   \n",
       "2                4     260041            267608                41275  ...   \n",
       "3                4          0                 0                38121  ...   \n",
       "4                4      92635             92635                44356  ...   \n",
       "...            ...        ...               ...                  ...  ...   \n",
       "6509             5      15590             15590                60939  ...   \n",
       "6510             5     951889            967479                62428  ...   \n",
       "6511             1          0                 0                52286  ...   \n",
       "6512             1       1057              1057                53343  ...   \n",
       "6513             1     284505            285562                78648  ...   \n",
       "\n",
       "      Cust_o  Cust_p  Cust_q  Next_Activity  Next_Act_!  Next_Act_A   \n",
       "0          0       0       0              B         0.0         0.0  \\\n",
       "1          0       0       0              C         0.0         0.0   \n",
       "2          0       0       0              !         1.0         0.0   \n",
       "3          0       0       0              B         0.0         0.0   \n",
       "4          0       0       0              C         0.0         0.0   \n",
       "...      ...     ...     ...            ...         ...         ...   \n",
       "6509       1       0       0              C         0.0         0.0   \n",
       "6510       1       0       0              !         1.0         0.0   \n",
       "6511       0       0       1              B         0.0         0.0   \n",
       "6512       0       0       1              C         0.0         0.0   \n",
       "6513       0       0       1              !         1.0         0.0   \n",
       "\n",
       "      Next_Act_B  Next_Act_C  Next_Act_D  Position  \n",
       "0            1.0         0.0         0.0         1  \n",
       "1            0.0         1.0         0.0         2  \n",
       "2            0.0         0.0         0.0         3  \n",
       "3            1.0         0.0         0.0         1  \n",
       "4            0.0         1.0         0.0         2  \n",
       "...          ...         ...         ...       ...  \n",
       "6509         0.0         1.0         0.0         2  \n",
       "6510         0.0         0.0         0.0         3  \n",
       "6511         1.0         0.0         0.0         1  \n",
       "6512         0.0         1.0         0.0         2  \n",
       "6513         0.0         0.0         0.0         3  \n",
       "\n",
       "[6514 rows x 48 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4366, 9, 9)\n",
      "This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): (4366, 9, 9) => True\n",
      "Shape of y_train_a: (4366, 5), this matches the desired shape (number_of_train_cases, target_act_length): (4366, 5) => True\n",
      "Shape of y_train_t: (4366,), this matches the desired shape (number_of_train_cases, ): (4366,) => True\n",
      "Shape of y_train_tr: (4366,), this matches the desired shape (number_of_train_cases, ): (4366,) => True\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train_a, y_train_t, y_train_tr = inbu.generating_inputs(OCEL=ocel_train,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR, \n",
    "                                                                  single= single_log)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): {(number_of_train_cases, max_trace_length, num_of_features)} => {X_train.shape ==(number_of_train_cases, max_trace_length, num_of_features)}\")\n",
    "print(f\"Shape of y_train_a: {y_train_a.shape}, this matches the desired shape (number_of_train_cases, target_act_length): {(number_of_train_cases, target_act_length)} => {y_train_a.shape ==(number_of_train_cases, target_act_length)}\")\n",
    "print(f\"Shape of y_train_t: {y_train_t.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_t.shape ==(number_of_train_cases, )}\")\n",
    "print(f\"Shape of y_train_tr: {y_train_tr.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_tr.shape ==(number_of_train_cases, )}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       ],\n",
       "       [1.       , 0.       , 0.       , 0.       , 1.       , 0.       ,\n",
       "        0.       , 0.3804051, 0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if single_log:\n",
    "    model_file = csvname + '_single'\n",
    "else:\n",
    "    model_file = csvname + '_enriched'\n",
    "# history = LSTM_model.LSTM_MODEL(X_train, y_train_a, y_train_t, y_train_tr,filename=model_file)\n",
    "# print(history.history.keys())\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 4ms/step\n",
      "2.604857336903863\n",
      "3.197816839635765\n",
      "4.759801071662072\n",
      "8.059703481044945\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from jellyfish import damerau_levenshtein_distance, levenshtein_distance\n",
    "import pandas as pd\n",
    "import distance\n",
    "\n",
    "modelname = 'model_Orders_filter_single_128-1.30.h5'\n",
    "model = load_model(f'./output_files/models/{modelname}')\n",
    "\n",
    "X_test,y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(OCEL=ocel_test,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR, \n",
    "                                                                  single= single_log)\n",
    "\n",
    "# y_t = y_t * divisor3\n",
    "\n",
    "y = model.predict(X_test,verbose=1)\n",
    "y_char = y[0][:][:]\n",
    "y_t = y[1][:][:]\n",
    "y_tr = y[2][:][:]\n",
    "max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "y_t = np.maximum(y_t, 0)\n",
    "y_t1 = y_t * divisor\n",
    "y_tr1 = y_tr * divisorTR\n",
    "\n",
    "columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                  [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                  ['Items', 'Customers', 'Packages', 'Next_Time_Since_Start',\n",
    "                   'Next_Time_Since_Midnight', 'Next_Weekday', 'In_Package',\n",
    "                   'Position', 'Time_Since_Midnight', 'Weekday', 'Amount_Items']\n",
    "\n",
    "output_ocel = ocel_test.drop(columns=columns_to_drop).copy()\n",
    "output_ocel['Pred_Activity'] = pred_act_list\n",
    "output_ocel['Pred_Time_Diff'] = y_t1\n",
    "output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "output_ocel\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print(metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60)))\n",
    "print(metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60)))\n",
    "print(metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60),squared=False))\n",
    "print(metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60),squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Prefix Length 2:\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "Results for Prefix Length 3:\n",
      "68/68 [==============================] - 0s 2ms/step\n",
      "Results for Prefix Length 4:\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "Results for Prefix Length 5:\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "Results for Prefix Length 6:\n",
      "68/68 [==============================] - 0s 4ms/step\n",
      "Results for Prefix Length 7:\n",
      "68/68 [==============================] - 0s 4ms/step\n",
      "Results for Prefix Length 8:\n",
      "68/68 [==============================] - 0s 4ms/step\n",
      "\n",
      "Overall Results:\n",
      "   Prefix Length  length  MAE Time Difference  MAE Remaining Time   \n",
      "0              2    2148             2.618566            3.179987  \\\n",
      "1              3    2148             2.609743            3.179557   \n",
      "2              4    2148             2.609162            3.189315   \n",
      "3              5    2148             2.606062            3.194762   \n",
      "4              6    2148             2.605464            3.196503   \n",
      "5              7    2148             2.604769            3.196662   \n",
      "6              8    2148             2.604857            3.197817   \n",
      "\n",
      "   RMSE Time Difference  RMSE Remaining Time  \n",
      "0              4.793733             8.264217  \n",
      "1              4.756484             8.154092  \n",
      "2              4.763754             8.099298  \n",
      "3              4.758774             8.073034  \n",
      "4              4.757932             8.065366  \n",
      "5              4.758627             8.064077  \n",
      "6              4.759801             8.059703  \n"
     ]
    }
   ],
   "source": [
    "from jellyfish import damerau_levenshtein_distance, levenshtein_distance\n",
    "import pandas as pd\n",
    "import distance\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate inputs with varying prefix lengths\n",
    "prefix_lengths = range(2, max_trace_length)  # List of prefix lengths to consider\n",
    "results = []\n",
    "\n",
    "for prefix_length in prefix_lengths:\n",
    "    print(f\"Results for Prefix Length {prefix_length}:\")\n",
    "    \n",
    "    # Generate inputs with the current prefix length\n",
    "    X_test, y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(OCEL=ocel_test,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR,\n",
    "                                                                  single=single_log,\n",
    "                                                                  prefix_length=prefix_length)\n",
    "\n",
    "    # Make predictions with the model\n",
    "    y = model.predict(X_test, verbose=1)\n",
    "    y_char = y[0][:][:]\n",
    "    y_t = y[1][:][:]\n",
    "    y_tr = y[2][:][:]\n",
    "\n",
    "    max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "    pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "    y_t = np.maximum(y_t, 0)\n",
    "    y_t1 = y_t * divisor\n",
    "    y_tr1 = y_tr * divisorTR\n",
    "\n",
    "    columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                      [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                      ['Items', 'Customers', 'Packages', 'Next_Time_Since_Start',\n",
    "                       'Next_Time_Since_Midnight', 'Next_Weekday', 'In_Package',\n",
    "                       'Position', 'Time_Since_Midnight', 'Weekday', 'Amount_Items']\n",
    "\n",
    "    output_ocel = ocel_test.drop(columns=columns_to_drop).copy()\n",
    "    output_ocel['Pred_Activity'] = pred_act_list\n",
    "    output_ocel['Pred_Time_Diff'] = y_t1\n",
    "    output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "    output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "    output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "    mae_time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60)) \n",
    "    mae_remaining_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60)) \n",
    "    rmse_time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60), squared=False) \n",
    "    rmse_remaining_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60), squared=False) \n",
    "\n",
    "    # Store the results for the current prefix length\n",
    "    results.append({\n",
    "        'Prefix Length': prefix_length,\n",
    "        'length': len(y_tr),\n",
    "        'MAE Time Difference': mae_time_diff,\n",
    "        'MAE Remaining Time': mae_remaining_time,\n",
    "        'RMSE Time Difference': rmse_time_diff,\n",
    "        'RMSE Remaining Time': rmse_remaining_time\n",
    "    })\n",
    "\n",
    "    # Output additional values based on Case_ID and prefix length\n",
    "    for case_id in output_ocel['Case_ID'].unique():\n",
    "        case_data = output_ocel[output_ocel['Case_ID'] == case_id]\n",
    "        trace_length = len(case_data)\n",
    "        if prefix_length <= trace_length:\n",
    "            # print(f\"\\nAdditional values for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            case_data_prefix = case_data[:prefix_length]\n",
    "            #print(case_data_prefix.to_string(index=False))\n",
    "            \n",
    "            mae_time_diff_case = metrics.mean_absolute_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "            mae_remaining_time_case = metrics.mean_absolute_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "            rmse_time_diff_case = metrics.mean_squared_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60), squared=False)\n",
    "            rmse_remaining_time_case = metrics.mean_squared_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60), squared=False)\n",
    "            \n",
    "            # print(f\"\\nMetrics for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            # print(\"MAE Time Difference:\", mae_time_diff_case)\n",
    "            # print(\"MAE Remaining Time:\", mae_remaining_time_case)\n",
    "            # print(\"RMSE Time Difference:\", rmse_time_diff_case)\n",
    "            # print(\"RMSE Remaining Time:\", rmse_remaining_time_case)\n",
    "\n",
    "# Output the overall results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import timedelta\n",
    "import distance\n",
    "from jellyfish import damerau_levenshtein_distance\n",
    "from keras.models import load_model\n",
    "from numpy.compat import unicode\n",
    "from sklearn import metrics\n",
    "\n",
    "modelname = 'model_Orders_filter_single_128-1.30.h5'\n",
    "model = load_model(f'./output_files/models/{modelname}')\n",
    "\n",
    "predict_size = max_trace_length\n",
    "\n",
    "# Get all unique activities in the DataFrame\n",
    "chars = sorted(set(ocel['Activity'].unique()))\n",
    "# Add '!' to the target_chars\n",
    "target_chars = chars + ['!']\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "target_indices = dict((c, i) for i, c in enumerate(target_chars))\n",
    "target_indices_char = dict((i,c) for i, c in enumerate(target_chars))\n",
    "\n",
    "\n",
    "# define helper functions\n",
    "def encode(sentence, times, times3, maxlen=max_trace_length):\n",
    "    num_features = len(chars) + 5\n",
    "    X = np.zeros((1, max_trace_length, num_features), dtype=np.float32)\n",
    "    leftpad = max_trace_length - len(sentence)\n",
    "    times2 = np.cumsum(times)\n",
    "    for t, char in enumerate(sentence):\n",
    "        midnight = times3[t].replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        timesincemidnight = times3[t] - midnight\n",
    "        for c in chars:\n",
    "            if c == char:\n",
    "                X[0, t + leftpad, char_indices[c]] = 1\n",
    "        X[0, t + leftpad, len(chars)] = t + 1\n",
    "        X[0, t + leftpad, len(chars) + 1] = times[t] / divisor\n",
    "        X[0, t + leftpad, len(chars) + 2] = times2[t] / divisor2\n",
    "        X[0, t + leftpad, len(chars) + 3] = timesincemidnight.seconds / 86400\n",
    "        X[0, t + leftpad, len(chars) + 4] = times3[t].weekday() / 7\n",
    "    return X\n",
    "\n",
    "\n",
    "def getSymbol(predictions):\n",
    "    maxPrediction = 0\n",
    "    symbol = ''\n",
    "    i = 0\n",
    "    for prediction in predictions:\n",
    "        if prediction >= maxPrediction:\n",
    "            maxPrediction = prediction\n",
    "            symbol = target_indices_char[i]\n",
    "        i += 1\n",
    "    return symbol\n",
    "\n",
    "\n",
    "one_ahead_gt = []\n",
    "one_ahead_pred = []\n",
    "\n",
    "two_ahead_gt = []\n",
    "two_ahead_pred = []\n",
    "\n",
    "three_ahead_gt = []\n",
    "three_ahead_pred = []\n",
    "flag = False\n",
    "# Preallocate lists for storing results\n",
    "results = []\n",
    "with open('./output_files/results/suffix_and_remaining_time_%s.csv' % csvname, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"CaseID\", \"Prefix length\", \"Ground truth\", \"Predicted\", \"Levenshtein\", \"Damerau\", \"Jaccard\",\n",
    "                         \"Ground truth times\", \"Predicted times\", \"RMSE\", \"MAE\"])\n",
    "\n",
    "# Get relevant columns from the grouped data\n",
    "group_columns = ['Case_ID', 'Activity', 'Time_Diff', 'Time_Since_Start', 'Timestamp']\n",
    "grouped_data = ocel_test.groupby('Case_ID')[group_columns]\n",
    "\n",
    "# Iterate over different prefix sizes\n",
    "for prefix_size in range(2, max_trace_length):\n",
    "    print(prefix_size)\n",
    "    \n",
    "    # Iterate over each case\n",
    "    for case_id, group in grouped_data:\n",
    "        if case_id == '990265':\n",
    "            flag = True\n",
    "            break\n",
    "        line = group['Activity'].values\n",
    "        Ptimes = group['Time_Diff'].values\n",
    "        Ptimes2 = group['Time_Since_Start'].values\n",
    "        Ptimes3 = pd.to_datetime(group['Timestamp']).dt.to_pydatetime().tolist()\n",
    "\n",
    "        Ptimes = np.append(Ptimes, 0)\n",
    "        cropped_line = ''.join(line[:prefix_size])\n",
    "        cropped_times = Ptimes[:prefix_size]\n",
    "        cropped_times3 = Ptimes3[:prefix_size]  # Convert numpy.datetime64 array to list\n",
    "\n",
    "        if len(Ptimes2) < prefix_size:\n",
    "            continue  # make no prediction for this case, since this case has ended already\n",
    "\n",
    "        ground_truth = ''.join(line[prefix_size:prefix_size + predict_size])\n",
    "        ground_truth_t = Ptimes2[prefix_size - 1]\n",
    "        case_end_time = Ptimes2[-1]\n",
    "        ground_truth_t = case_end_time - ground_truth_t\n",
    "\n",
    "        predicted = ''\n",
    "        total_predicted_time = 0\n",
    "\n",
    "        for i in range(predict_size):\n",
    "            enc = encode(cropped_line, cropped_times, cropped_times3)\n",
    "            y = model.predict(enc, verbose=0)  # make predictions\n",
    "\n",
    "            # split predictions into separate activity and time predictions\n",
    "            y_char = y[0][0]\n",
    "            y_t = y[1][0][0]\n",
    "            prediction = getSymbol(y_char)  # undo one-hot encoding\n",
    "            cropped_line += prediction\n",
    "\n",
    "            y_t = np.maximum(y_t, 0)\n",
    "            y_t1 = y_t * divisor\n",
    "            cropped_times = np.append(cropped_times, y_t1)\n",
    "\n",
    "            if prediction == '!':  # end of case was just predicted, therefore, stop predicting further into the future\n",
    "                one_ahead_pred.append(total_predicted_time)\n",
    "                one_ahead_gt.append(ground_truth_t)\n",
    "                print('! predicted, end case')\n",
    "                break\n",
    "\n",
    "            y_t = y_t * divisor3\n",
    "            next_time = cropped_times3[-1] + timedelta(seconds=y_t)\n",
    "            cropped_times3.append(next_time)  # Append new datetime object\n",
    "            total_predicted_time += y_t\n",
    "            predicted += prediction\n",
    "\n",
    "        output = []\n",
    "        if len(ground_truth) > 0:\n",
    "            output.append(case_id)\n",
    "            output.append(prefix_size)\n",
    "            output.append(str(ground_truth))\n",
    "            output.append(str(predicted))\n",
    "            output.append(1 - distance.nlevenshtein(predicted, ground_truth))\n",
    "            dls = 1 - (damerau_levenshtein_distance(str(predicted), str(ground_truth)) / max(len(predicted), len(ground_truth)))\n",
    "            dls = np.maximum(dls, 0)\n",
    "            output.append(dls)\n",
    "            output.append(1 - distance.jaccard(predicted, ground_truth))\n",
    "            output.append(ground_truth_t)\n",
    "            output.append(total_predicted_time)\n",
    "            output.append('')\n",
    "            output.append(metrics.mean_absolute_error([ground_truth_t], [total_predicted_time]))\n",
    "            results.append(output)\n",
    "\n",
    "    if flag:\n",
    "        break\n",
    "with open('./output_files/results/suffix_and_remaining_time_%s.csv' % csvname, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # Write results to CSV\n",
    "    spamwriter.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 990265 in 35\n",
    "# in 36.3 new in 34\n",
    "\n",
    "#         if flag:\n",
    "#             break \n",
    "#         # Iterate over each case\n",
    "#         for case_id, group in grouped_data:\n",
    "#             if case_id == '990265':\n",
    "#                 flag = True\n",
    "#                 break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
