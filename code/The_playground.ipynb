{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import (prep, folding, inbu, LSTM_model)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from jellyfish import damerau_levenshtein_distance, levenshtein_distance\n",
    "import distance\n",
    "from sklearn import metrics\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"running-example\"\n",
    "flatten_by = 'Packages' # input(\"Enter the value for flatten_by (Orders, Items or Packages): \")\n",
    "single_log = 'True' # input(\"Enter the value for single_log (True/False): \")\n",
    "if flatten_by == 'Packages':\n",
    "    complete = 'True'\n",
    "else:\n",
    "    complete = 'False' # input(\"Enter the value for complete (True/False): \")\n",
    "testing_other_remaining = False\n",
    "add_customer = 1\n",
    "normalize = False\n",
    "# Error handling for invalid input values\n",
    "if flatten_by not in ['Orders', 'Items', 'Packages']:\n",
    "    raise ValueError(\"Wrong Input: flatten_by must be one of ['Orders', 'Items', 'Packages']\")\n",
    "\n",
    "if single_log.lower() not in ['true', 'false', '1', '0']:\n",
    "    raise ValueError(\"Wrong Input: single_log must be a boolean value (True/False)\")\n",
    "\n",
    "if complete.lower() not in ['true', 'false', '1', '0']:\n",
    "    raise ValueError(\"Wrong Input: complete must be a boolean value (True/False)\")\n",
    "\n",
    "# Convert input values to boolean\n",
    "single_log = single_log.lower() in ['true', '1']\n",
    "complete = complete.lower() in ['true', '1'] \n",
    "if complete:\n",
    "    csvname = flatten_by  + '_complete'\n",
    "    fl = None\n",
    "else:\n",
    "    csvname = flatten_by  + '_filter'\n",
    "    fl = prep.act_filter(flatten_by )\n",
    "\n",
    "time_feat = ['Time_Diff', 'Time_Since_Start', 'Time_Since_Midnight','Weekday','Position']\n",
    "other_features = [] + int(flatten_by != 'Items') * ['Amount_Items'] + int(flatten_by != 'Packages') * ['In_Package'] + int(flatten_by != 'Orders') * ['Amount_Orders']\n",
    "drops_col_order = [\"weight\", \"price\", \"Event_ID\", 'Products']\n",
    "print(\"Settings:\")\n",
    "print(f\"flatten_by: {flatten_by}\")\n",
    "print(f\"single_log: {single_log}\")\n",
    "print(f\"complete: {complete}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prep the ocel and reading\n",
    "ocel, act_dict, cust_dict = prep.prepare_flat_ocel(source, flatten_on= flatten_by , filter= fl)\n",
    "print(act_dict)\n",
    "print(cust_dict)\n",
    "## create the enriched and some more preprocessing as well as saving the single and enriched versions\n",
    "ocel = prep.gen_enriched_single_plus_csv(OCEL = ocel,flatted_by = flatten_by ,csvname = csvname, drops_col= drops_col_order, single=single_log)\n",
    "## adding features\n",
    "ocel =prep.generate_features(ocel, single= single_log)\n",
    "## define some static variables \n",
    "divisor = np.mean(ocel['Time_Diff'])  # average time between events\n",
    "divisor2 = np.mean(ocel['Time_Since_Start'])  # average time between current and first events\n",
    "divisorTR = np.mean(ocel['Remaining_Time'])  # average time instance remaining\n",
    "divisor3 = ocel.groupby('Case_ID')['Time_Since_Start'].apply(lambda x: (x.iloc[-1] - x).mean()).mean()\n",
    "\n",
    "print(f\"divisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "print(f\"divisor3: {divisor3}\")\n",
    "print(f'Amount of rows of the OCEL: {len(ocel)}')\n",
    "#folding the data \n",
    "ocel_train, ocel_test = folding.folding_train_test(ocel,old_ver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_feat = list(filter(lambda k: k.startswith('Act_') and not k.startswith('Next_Act_'), ocel_train.columns))\n",
    "act_feat.remove('Act_!')\n",
    "act_feat_dict = {index: value.replace('Act_', '') for index, value in enumerate(act_feat)}\n",
    "target_act_feat = list(filter(lambda k: k.startswith('Next_Act_') and not k.startswith('Act_'), ocel_train.columns))\n",
    "target_act_feat_dict = {index: value.replace('Next_Act_', '') for index, value in enumerate(target_act_feat)}\n",
    "\n",
    "cust_feat = list(filter(lambda k: 'Cust_' in k, ocel_train.columns)) * (1 - int(single_log)) * add_customer\n",
    "\n",
    "feature_select = act_feat + time_feat + other_features *(1 - int(single_log)) + cust_feat *(1 - int(single_log))\n",
    "print(f\"Length of act_feat: {len(act_feat)}, Length of cust_feat: {len(cust_feat)}\")\n",
    "\n",
    "## define dimensions of inputs\n",
    "max_trace_length = prep.gen_traces_and_maxlength_of_trace(ocel)[1]\n",
    "target_act_length = len(target_act_feat)\n",
    "number_of_train_cases = len(ocel_train)\n",
    "num_of_features = len(feature_select) if 'In_Package' not in ocel.columns else len(feature_select) - (len(ocel['In_Package'].unique()) == 1)\n",
    "print(f\"Number of train cases: {number_of_train_cases}, Max trace length: {max_trace_length}, Number of features: {num_of_features}\")\n",
    "print(target_act_feat_dict)\n",
    "print(act_feat_dict)\n",
    "print(cust_feat)\n",
    "print(num_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train_a, y_train_t, y_train_tr = inbu.generating_inputs(OCEL=ocel_train,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR,\n",
    "                                                                  normalize = normalize, \n",
    "                                                                  test = testing_other_remaining)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): {(number_of_train_cases, max_trace_length, num_of_features)} => {X_train.shape ==(number_of_train_cases, max_trace_length, num_of_features)}\")\n",
    "print(f\"Shape of y_train_a: {y_train_a.shape}, this matches the desired shape (number_of_train_cases, target_act_length): {(number_of_train_cases, target_act_length)} => {y_train_a.shape ==(number_of_train_cases, target_act_length)}\")\n",
    "print(f\"Shape of y_train_t: {y_train_t.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_t.shape ==(number_of_train_cases, )}\")\n",
    "print(f\"Shape of y_train_tr: {y_train_tr.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_tr.shape ==(number_of_train_cases, )}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if single_log:\n",
    "    model_file = csvname + '_single'\n",
    "else:\n",
    "    model_file = csvname + '_enriched'\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, best_model_name, early_stopping= LSTM_model.LSTM_MODEL(X_train, y_train_a, y_train_t, y_train_tr,filename=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model_name.best)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "epoch = early_stopping.stopped_epoch - 50\n",
    "val_loss = min(history.history['val_loss'])\n",
    "\n",
    "modelname = model_file + f\"_{epoch:02d}-{val_loss:.2f}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'model_Packages_complete_single_87-1.15.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ocel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'./output_files/models/{modelname}')\n",
    "X_test,y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(OCEL=ocel_test,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR, \n",
    "                                                                  normalize = normalize, \n",
    "                                                                  test = testing_other_remaining)\n",
    "\n",
    "# y_t = y_t * divisor3\n",
    "\n",
    "y = model.predict(X_test,verbose=1)\n",
    "y_char = y[0][:][:]\n",
    "y_t = y[1][:][:]\n",
    "y_tr = y[2][:][:]\n",
    "max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "y_t = np.maximum(y_t, 0)\n",
    "y_t1 = y_t * divisor\n",
    "y_tr1 = y_tr * divisorTR\n",
    "\n",
    "columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                  [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                  ['Customers', 'Next_Time_Since_Start',\n",
    "                   'Next_Time_Since_Midnight', 'Next_Weekday',\n",
    "                   'Position', 'Time_Since_Midnight', 'Weekday'] + other_features\n",
    "\n",
    "columns_to_drop_existing = [col for col in columns_to_drop if col in ocel_test.columns]\n",
    "output_ocel = ocel_test.drop(columns=columns_to_drop_existing).copy()\n",
    "output_ocel['Pred_Activity'] = pred_act_list\n",
    "output_ocel['Pred_Time_Diff'] = y_t1 \n",
    "output_ocel['Pred_Remaining_Time'] = y_tr1 \n",
    "\n",
    "output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "output_ocel\n",
    "from sklearn import metrics\n",
    "act_comp = output_ocel['Pred_Activity'] == output_ocel['Next_Activity'] \n",
    "print(f'The accuracy of the activation prediction is {sum(act_comp)/len(act_comp)}')\n",
    "MAE_Time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "MAE_rem_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "RMSE_Time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60),squared=False)\n",
    "RMSE_rem_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60),squared=False)\n",
    "print(f'MAE of the time between events in days {MAE_Time_diff}')\n",
    "print(f'MAE of the remaining time in days {MAE_rem_time}')\n",
    "# print(f'RMSE of the time between events in days {RMSE_Time_diff}')\n",
    "# print(f'RMSE of the remaining time in days {RMSE_rem_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ocel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate inputs with varying prefix lengths\n",
    "prefix_lengths = range(2, max_trace_length-1)  # List of prefix lengths to consider\n",
    "results = []\n",
    "\n",
    "for prefix_length in prefix_lengths:\n",
    "    print(f\"Results for Prefix Length {prefix_length}:\")\n",
    "    \n",
    "    # Generate inputs with the current prefix length\n",
    "    X_test, y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(OCEL=ocel_test,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  max_trace_length=max_trace_length,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR,\n",
    "                                                                  normalize = normalize, \n",
    "                                                                  prefix_length=prefix_length,\n",
    "                                                                  test = testing_other_remaining)\n",
    "\n",
    "    # Make predictions with the model\n",
    "    y = model.predict(X_test, verbose=1)\n",
    "    y_char = y[0][:][:]\n",
    "    y_t = y[1][:][:]\n",
    "    y_tr = y[2][:][:]\n",
    "\n",
    "    max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "    pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "    y_t = np.maximum(y_t, 0)\n",
    "    y_t1 = y_t * divisor\n",
    "    y_tr1 = y_tr * divisorTR\n",
    "\n",
    "    columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                    [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                    ['Customers', 'Next_Time_Since_Start',\n",
    "                    'Next_Time_Since_Midnight', 'Next_Weekday',\n",
    "                    'Position', 'Time_Since_Midnight', 'Weekday'] + other_features\n",
    "\n",
    "    columns_to_drop_existing = [col for col in columns_to_drop if col in ocel_test.columns]\n",
    "    trace_length = ocel_test['Trace_Len'].values\n",
    "    output_ocel = ocel_test[trace_length >= prefix_length].reset_index(drop= True).drop(columns=columns_to_drop_existing).copy()\n",
    "    output_ocel['Pred_Activity'] = pred_act_list\n",
    "    output_ocel['Pred_Time_Diff'] = y_t1\n",
    "    output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "    output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "    output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "    mae_time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60)) \n",
    "    mae_remaining_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60)) \n",
    "    rmse_time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60), squared=False) \n",
    "    rmse_remaining_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60), squared=False) \n",
    "    act_comp = output_ocel['Pred_Activity'] == output_ocel['Next_Activity'] \n",
    "    # Store the results for the current prefix length\n",
    "    results.append({\n",
    "        'Prefix Length': prefix_length,\n",
    "        'length': len(y_tr),\n",
    "        'Accuracy_Activity_pred': sum(act_comp)/len(act_comp),\n",
    "        'MAE_Time_Difference': mae_time_diff,\n",
    "        'MAE_Remaining_Time': mae_remaining_time,\n",
    "        'RMSE_Time_Difference': rmse_time_diff,\n",
    "        'RMSE_Remaining_Time': rmse_remaining_time\n",
    "    })\n",
    "\n",
    "    # Output additional values based on Case_ID and prefix length\n",
    "    for case_id in output_ocel['Case_ID'].unique():\n",
    "        case_data = output_ocel[output_ocel['Case_ID'] == case_id]\n",
    "        trace_length = len(case_data)\n",
    "        if prefix_length <= trace_length:\n",
    "            # print(f\"\\nAdditional values for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            case_data_prefix = case_data[:prefix_length]\n",
    "            #print(case_data_prefix.to_string(index=False))\n",
    "            \n",
    "            mae_time_diff_case = metrics.mean_absolute_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "            mae_remaining_time_case = metrics.mean_absolute_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "            rmse_time_diff_case = metrics.mean_squared_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60), squared=False)\n",
    "            rmse_remaining_time_case = metrics.mean_squared_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60), squared=False)\n",
    "            \n",
    "            # print(f\"\\nMetrics for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            # print(\"MAE Time Difference:\", mae_time_diff_case)\n",
    "            # print(\"MAE Remaining Time:\", mae_remaining_time_case)\n",
    "            # print(\"RMSE Time Difference:\", rmse_time_diff_case)\n",
    "            # print(\"RMSE Remaining Time:\", rmse_remaining_time_case)\n",
    "\n",
    "# Output the overall results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results ['MAE_Remaining_Time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Sample data dictionary\n",
    "data = {\n",
    "    'num_of_features': num_of_features,\n",
    "    'max_trace_length': max_trace_length,\n",
    "    'target_act_feat': target_act_feat,\n",
    "    'act_feat': act_feat,\n",
    "    'cust_feat': cust_feat,\n",
    "    'divisor': divisor,\n",
    "    'divisor2': divisor2,\n",
    "    'divisorTR': divisorTR,\n",
    "    'single_log': single_log,\n",
    "    'target_act_feat_dict': target_act_feat_dict,\n",
    "    'modelname': modelname\n",
    "}\n",
    "\n",
    "# Write data to a file using pickle\n",
    "with open('output_files/settings.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "# Read data from the file\n",
    "with open('output_files/settings.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Print the loaded data and their types\n",
    "for key, value in loaded_data.items():\n",
    "    print(f'{key}: {type(value)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
