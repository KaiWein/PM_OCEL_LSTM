{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from functions import (prep, folding, inbu, LSTM_model,setting)\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from jellyfish import damerau_levenshtein_distance, levenshtein_distance\n",
    "import pandas as pd\n",
    "import distance\n",
    "from sklearn import metrics\n",
    "np.random.seed(42)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "flatten_by: Packages\n",
      "single_log: False\n",
      "complete: True\n",
      "Add customer: True\n",
      "Normalize: True\n",
      "Position excluded: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "setting_inputs = setting.inputdef()\n",
    "csvname = f\"{setting_inputs['flatten_by']}_complete\" if setting_inputs['complete'] else f\"{setting_inputs['flatten_by']}_filter\"\n",
    "# Define model_file based on single_log value\n",
    "model_file = f\"{csvname}_single\" if setting_inputs['single_log'] else f\"{csvname}_enriched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'running-example',\n",
       " 'add_customer': 1,\n",
       " 'normalize': True,\n",
       " 'pos_ex': False,\n",
       " 'flatten_by': 'Packages',\n",
       " 'single_log': False,\n",
       " 'complete': True}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setting_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place order': 'A', 'pick item': 'B', 'confirm order': 'C', 'item out of stock': 'D', 'reorder item': 'E', 'pay order': 'F', 'create package': 'G', 'send package': 'H', 'failed delivery': 'I', 'package delivered': 'J', 'payment reminder': 'K'}\n",
      "{'Marco Pegoraro': 'a', 'Gyunam Park': 'b', 'Majid Rafiei': 'c', 'Junxiong Gao': 'd', 'Seran Uysal': 'e', 'Christina Rensinghof': 'f', 'Wil van der Aalst': 'g', 'Christine Dobbert': 'h', 'Luis Santos': 'i', 'Kefang Ding': 'j', 'Mohammadreza Fani Sani': 'k', 'Tobias Brockhoff': 'l', 'Anahita Farhang Ghahfarokhi': 'm', 'Mahnaz Qafari': 'n', 'Claudia Graf': 'o', 'Mahsa Bafrani': 'p', 'Lisa Mannel': 'q'}\n",
      "\n",
      "divisor: 47402.199267063676\n",
      "divisor2: 83320.73980760422\n",
      "divisorTR: 82686.42281264316\n",
      "divisor3: 77428.97973944295\n",
      "Amount of rows of the OCEL: 4366\n",
      "\n",
      "Length of act_feat: 4, Length of cust_feat: 17\n",
      "Number of train cases: 2913, Max trace length: 9, Number of features: 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prep the ocel and reading\n",
    "ocel, act_dict, cust_dict = prep.prep_ocel_complete(setting_inputs=setting_inputs,csvname=csvname)\n",
    "ocel_train, ocel_test = folding.folding_train_test(ocel, csvname= model_file)\n",
    "## define some static variables \n",
    "divisor = np.mean(ocel['Time_Diff'])  # average time between events\n",
    "divisor2 = np.mean(ocel['Time_Since_Start'])  # average time between current and first events\n",
    "divisorTR = np.mean(ocel['Remaining_Time'])  # average time instance remaining\n",
    "divisor3 = ocel.groupby('Case_ID')['Time_Since_Start'].apply(lambda x: (x.iloc[-1] - x).mean()).mean()\n",
    "\n",
    "print(f\"\\ndivisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "print(f\"divisor3: {divisor3}\")\n",
    "print(f'Amount of rows of the OCEL: {len(ocel)}\\n')\n",
    "\n",
    "num_of_features, max_trace_length, act_feat,cust_feat, target_act_feat, target_act_feat_dict, other_features = setting.feature_dimensios(ocel=ocel,setting_input=setting_inputs)\n",
    "number_of_train_cases = len(ocel_train)\n",
    "target_act_length = len(target_act_feat)\n",
    "print(f\"Number of train cases: {number_of_train_cases}, Max trace length: {max_trace_length}, Number of features: {num_of_features}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of act_feat: 4, Length of cust_feat: 17\n",
      "Shape of X_train: (2913, 9, 28)\n",
      "This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): (2913, 9, 28) => True\n",
      "Shape of y_train_a: (2913, 5), this matches the desired shape (number_of_train_cases, target_act_length): (2913, 5) => True\n",
      "Shape of y_train_t: (2913,), this matches the desired shape (number_of_train_cases, ): (2913,) => True\n",
      "Shape of y_train_tr: (2913,), this matches the desired shape (number_of_train_cases, ): (2913,) => True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train_a, y_train_t, y_train_tr = inbu.generating_inputs(ocel_fold=ocel_train,ocel=ocel,setting_input=setting_inputs,\n",
    "                                                                  dn= divisor, ds= divisor2, dr= divisorTR)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): {(number_of_train_cases, max_trace_length, num_of_features)} => {X_train.shape ==(number_of_train_cases, max_trace_length, num_of_features)}\")\n",
    "print(f\"Shape of y_train_a: {y_train_a.shape}, this matches the desired shape (number_of_train_cases, target_act_length): {(number_of_train_cases, target_act_length)} => {y_train_a.shape ==(number_of_train_cases, target_act_length)}\")\n",
    "print(f\"Shape of y_train_t: {y_train_t.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_t.shape ==(number_of_train_cases, )}\")\n",
    "print(f\"Shape of y_train_tr: {y_train_tr.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_tr.shape ==(number_of_train_cases, )}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following setting a model is now trained Packages_complete_enriched\n",
      "\n",
      "Build model...\n",
      "Epoch 1/500\n",
      "259/259 - 13s - loss: 1.9391 - act_output_loss: 0.6424 - time_output_loss: 0.8805 - timeR_output_loss: 0.4161 - val_loss: 1.3022 - val_act_output_loss: 0.1982 - val_time_output_loss: 0.7714 - val_timeR_output_loss: 0.3326\n",
      "Epoch 2/500\n",
      "259/259 - 4s - loss: 1.5363 - act_output_loss: 0.3071 - time_output_loss: 0.8441 - timeR_output_loss: 0.3850 - val_loss: 1.2838 - val_act_output_loss: 0.1811 - val_time_output_loss: 0.7675 - val_timeR_output_loss: 0.3352\n",
      "Epoch 3/500\n",
      "259/259 - 3s - loss: 1.5085 - act_output_loss: 0.2984 - time_output_loss: 0.8332 - timeR_output_loss: 0.3769 - val_loss: 1.2537 - val_act_output_loss: 0.1740 - val_time_output_loss: 0.7590 - val_timeR_output_loss: 0.3206\n",
      "Epoch 4/500\n",
      "259/259 - 4s - loss: 1.4777 - act_output_loss: 0.2789 - time_output_loss: 0.8259 - timeR_output_loss: 0.3729 - val_loss: 1.2519 - val_act_output_loss: 0.1727 - val_time_output_loss: 0.7576 - val_timeR_output_loss: 0.3215\n",
      "Epoch 5/500\n",
      "259/259 - 4s - loss: 1.4722 - act_output_loss: 0.2801 - time_output_loss: 0.8206 - timeR_output_loss: 0.3715 - val_loss: 1.2572 - val_act_output_loss: 0.1819 - val_time_output_loss: 0.7547 - val_timeR_output_loss: 0.3206\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFor the following setting a model is now trained \u001b[39m\u001b[39m{\u001b[39;00mmodel_file\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history, best_model_name, early_stopping\u001b[39m=\u001b[39m LSTM_model\u001b[39m.\u001b[39;49mLSTM_MODEL(X_train, y_train_a, y_train_t, y_train_tr,filename\u001b[39m=\u001b[39;49mmodel_file)\n",
      "File \u001b[1;32mc:\\Users\\kwein\\UNI\\UniAachenRWTH\\Semester4\\SeminarPredictionandSimulation\\code\\PM_OCEL_LSTM\\code\\functions\\LSTM_model.py:43\u001b[0m, in \u001b[0;36mLSTM_MODEL\u001b[1;34m(X, y_a, y_t, y_tr, filename)\u001b[0m\n\u001b[0;32m     38\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39m./output_files/models/model_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfilename\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{epoch:02d}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{val_loss:.2f}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     39\u001b[0m                                    verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m lr_reducer \u001b[39m=\u001b[39m ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, min_delta\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,\n\u001b[0;32m     41\u001b[0m                                cooldown\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, {\u001b[39m'\u001b[39;49m\u001b[39mact_output\u001b[39;49m\u001b[39m'\u001b[39;49m: y_a, \u001b[39m'\u001b[39;49m\u001b[39mtime_output\u001b[39;49m\u001b[39m'\u001b[39;49m: y_t, \u001b[39m'\u001b[39;49m\u001b[39mtimeR_output\u001b[39;49m\u001b[39m'\u001b[39;49m: y_tr}, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m     44\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[early_stopping, model_checkpoint, lr_reducer], batch_size\u001b[39m=\u001b[39;49mmax_trace_length, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n\u001b[0;32m     46\u001b[0m \u001b[39m# List all data in history\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m history, model_checkpoint, early_stopping\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1181\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1182\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1183\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1184\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1185\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1186\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1187\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1188\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1189\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\kwein\\anaconda3\\envs\\PM_OCEL_LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'For the following setting a model is now trained {model_file}\\n')\n",
    "history, best_model_name, early_stopping= LSTM_model.LSTM_MODEL(X_train, y_train_a, y_train_t, y_train_tr,filename=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m val_loss2 \u001b[39m=\u001b[39m best_model_name\u001b[39m.\u001b[39mbest\n\u001b[0;32m      3\u001b[0m epoch \u001b[39m=\u001b[39m early_stopping\u001b[39m.\u001b[39mstopped_epoch \u001b[39m-\u001b[39m \u001b[39m49\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "val_loss = min(history.history['val_loss'])\n",
    "val_loss2 = best_model_name.best\n",
    "epoch = early_stopping.stopped_epoch - 49\n",
    "print(f'The best value for the validation loss is  {val_loss} and was archived at the epoch {epoch}\\n')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "modelname = 'model_' + model_file + f\"_{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "\n",
    "print(f'The best model has the name {modelname}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'./output_files/models/{modelname}')\n",
    "X_test, y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(ocel_fold=ocel_test,ocel=ocel,setting_input=setting_inputs,\n",
    "                                                                  dn= divisor, ds= divisor2, dr= divisorTR)\n",
    "\n",
    "# y_t = y_t * divisor3\n",
    "y = model.predict(X_test,verbose=1)\n",
    "y_char = y[0][:][:]\n",
    "y_t = y[1][:][:]\n",
    "y_tr = y[2][:][:]\n",
    "max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "y_t = np.maximum(y_t, 0)\n",
    "y_t1 = y_t * divisor\n",
    "y_tr1 = y_tr * divisorTR\n",
    "\n",
    "columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                ['Customers', 'Next_Time_Since_Start',\n",
    "                'Next_Time_Since_Midnight', 'Next_Weekday',\n",
    "                'Position', 'Time_Since_Midnight', 'Weekday'] + other_features\n",
    "\n",
    "columns_to_drop_existing = [col for col in columns_to_drop if col in ocel_test.columns]\n",
    "output_ocel = ocel_test.drop(columns=columns_to_drop_existing).copy()\n",
    "output_ocel['Pred_Activity'] = pred_act_list\n",
    "output_ocel['Pred_Time_Diff'] = y_t1\n",
    "output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "act_comp = output_ocel['Pred_Activity'] == output_ocel['Next_Activity'] \n",
    "print(f'The accuracy of the activation prediction is {sum(act_comp)/len(act_comp)}')\n",
    "MAE_Time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "MAE_rem_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "RMSE_Time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60),squared=False)\n",
    "RMSE_rem_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60),squared=False)\n",
    "print(f'MAE of the time between events in days {MAE_Time_diff}')\n",
    "print(f'MAE of the remaining time in days {MAE_rem_time}')\n",
    "# print(f'RMSE of the time between events in days {RMSE_Time_diff}')\n",
    "# print(f'RMSE of the remaining time in days {RMSE_rem_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ocel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_lengths = range(2, max_trace_length-1)  # List of prefix lengths to consider\n",
    "results = []\n",
    "\n",
    "for prefix_length in prefix_lengths:\n",
    "    print(f\"Results for Prefix Length {prefix_length}:\")\n",
    "    \n",
    "    # Generate inputs with the current prefix length\n",
    "    X_test,y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(ocel_fold=ocel_test,ocel=ocel,setting_input=setting_inputs,\n",
    "                                                                  dn= divisor, ds= divisor2, dr= divisorTR,\n",
    "                                                                    prefix_length=prefix_length)\n",
    "    # Make predictions with the model\n",
    "    y = model.predict(X_test, verbose=1)\n",
    "    y_char = y[0][:][:]\n",
    "    y_t = y[1][:][:]\n",
    "    y_tr = y[2][:][:]\n",
    "\n",
    "    max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "    pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "    y_t = np.maximum(y_t, 0)\n",
    "    y_t1 = y_t * divisor\n",
    "    y_tr1 = y_tr * divisorTR\n",
    "\n",
    "    columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                    [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                    ['Customers', 'Next_Time_Since_Start',\n",
    "                    'Next_Time_Since_Midnight', 'Next_Weekday',\n",
    "                    'Position', 'Time_Since_Midnight', 'Weekday'] + other_features\n",
    "\n",
    "    columns_to_drop_existing = [col for col in columns_to_drop if col in ocel_test.columns]\n",
    "    trace_length = ocel_test['Trace_Len'].values\n",
    "    output_ocel = ocel_test[trace_length >= prefix_length].reset_index(drop= True).drop(columns=columns_to_drop_existing).copy()\n",
    "    output_ocel['Pred_Activity'] = pred_act_list\n",
    "    output_ocel['Pred_Time_Diff'] = y_t1\n",
    "    output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "    output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "    output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "    mae_time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60)) \n",
    "    mae_remaining_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60)) \n",
    "    rmse_time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60), squared=False) \n",
    "    rmse_remaining_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60), squared=False) \n",
    "\n",
    "    # Store the results for the current prefix length\n",
    "    results.append({\n",
    "        'Prefix Length': prefix_length,\n",
    "        'length': len(y_tr),\n",
    "        'MAE Time Difference': mae_time_diff,\n",
    "        'MAE Remaining Time': mae_remaining_time,\n",
    "        'RMSE Time Difference': rmse_time_diff,\n",
    "        'RMSE Remaining Time': rmse_remaining_time\n",
    "    })\n",
    "\n",
    "    # Output additional values based on Case_ID and prefix length\n",
    "    for case_id in output_ocel['Case_ID'].unique():\n",
    "        case_data = output_ocel[output_ocel['Case_ID'] == case_id]\n",
    "        trace_length = len(case_data)\n",
    "        if prefix_length <= trace_length:\n",
    "            # print(f\"\\nAdditional values for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            case_data_prefix = case_data[:prefix_length]\n",
    "            #print(case_data_prefix.to_string(index=False))\n",
    "            \n",
    "            mae_time_diff_case = metrics.mean_absolute_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "            mae_remaining_time_case = metrics.mean_absolute_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "            rmse_time_diff_case = metrics.mean_squared_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60), squared=False)\n",
    "            rmse_remaining_time_case = metrics.mean_squared_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60), squared=False)\n",
    "            \n",
    "            # print(f\"\\nMetrics for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            # print(\"MAE Time Difference:\", mae_time_diff_case)\n",
    "            # print(\"MAE Remaining Time:\", mae_remaining_time_case)\n",
    "            # print(\"RMSE Time Difference:\", rmse_time_diff_case)\n",
    "            # print(\"RMSE Remaining Time:\", rmse_remaining_time_case)\n",
    "\n",
    "# Output the overall results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "modelname = \"\"\n",
    "# Load the saved history from file\n",
    "with open(f'/ouput_files/history/{modelname}_history.pkl', 'rb') as file:\n",
    "    loaded_history = pickle.load(file)\n",
    "\n",
    "# Access the loaded history\n",
    "print(loaded_history)\n",
    "plt.plot(loaded_history['loss'])\n",
    "plt.plot(loaded_history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
