{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import (prep, folding, inbu, LSTM_model)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import session_info\n",
    "# session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place order': 'A', 'pick item': 'B', 'confirm order': 'C', 'item out of stock': 'D', 'reorder item': 'E', 'pay order': 'F', 'create package': 'G', 'send package': 'H', 'failed delivery': 'I', 'package delivered': 'J', 'payment reminder': 'K'}\n",
      "{'Marco Pegoraro': 'a', 'Gyunam Park': 'b', 'Majid Rafiei': 'c', 'Junxiong Gao': 'd', 'Seran Uysal': 'e', 'Christina Rensinghof': 'f', 'Wil van der Aalst': 'g', 'Christine Dobbert': 'h', 'Luis Santos': 'i', 'Kefang Ding': 'j', 'Mohammadreza Fani Sani': 'k', 'Tobias Brockhoff': 'l', 'Anahita Farhang Ghahfarokhi': 'm', 'Mahnaz Qafari': 'n', 'Claudia Graf': 'o', 'Mahsa Bafrani': 'p', 'Lisa Mannel': 'q'}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "filename = \"running-example\"\n",
    "flattent_by = 'Orders'\n",
    "ocel, act_dict, cust_dict = prep.prepare_flat_ocel(filename, flatten_on= flattent_by)\n",
    "print(act_dict)\n",
    "print(cust_dict)\n",
    "drops_col_order = [\"weight\", \"price\", \"Event_ID\", 'Products']\n",
    "enriched_log, single_log = prep.gen_enriched_single_plus_csv(OCEL = ocel,flatted_by = 'Orders',csvname = 'orders_complete', drops_col= drops_col_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 103436.38622985176\n",
      "divisor2: 604261.1036767652\n",
      "divisorTR: 1248093.355995932\n"
     ]
    }
   ],
   "source": [
    "enriched_log =prep.gen_features(enriched_log)\n",
    "divisor = np.mean(enriched_log['Time_Diff'])  # average time between events\n",
    "divisor2 = np.mean(enriched_log['Time_Since_Start'])  # average time between current and first events\n",
    "divisorTR = np.mean(enriched_log['Remaining_Time'])  # average time instance remaining\n",
    "print(f\"divisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "enr_train, enr_test = folding.folding_train_test(enriched_log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of act_feat: 11, Length of cust_feat: 18\n",
      "Number of train cases: 21620, Max trace length: 42, Number of features: 36\n"
     ]
    }
   ],
   "source": [
    "act_feat = list(filter(lambda k: k.startswith('Act_') and not k.startswith('Next_Act_'), enr_train.columns))\n",
    "target_act_feat = list(filter(lambda k: k.startswith('Next_Act_') and not k.startswith('Act_'), enr_train.columns))\n",
    "act_feat.remove('Act_!')\n",
    "cust_feat = list(filter(lambda k: 'Cust_' in k, enr_train.columns))\n",
    "time_feat = ['Time_Diff', 'Time_Since_Start', 'Time_Since_Midnight','Weekday']\n",
    "other_features = ['Amount_Items','In_Package','Position']\n",
    "feature_select = act_feat + cust_feat + time_feat + other_features\n",
    "print(f\"Length of act_feat: {len(act_feat)}, Length of cust_feat: {len(cust_feat)}\")\n",
    "\n",
    "## define dimensions of inputs\n",
    "traces, max_trace_length = prep.gen_traces_and_maxlength_of_trace(enriched_log)\n",
    "target_act_length = len(target_act_feat)\n",
    "number_of_train_cases = len(enr_train)\n",
    "num_of_features = len(feature_select)\n",
    "print(f\"Number of train cases: {number_of_train_cases}, Max trace length: {max_trace_length}, Number of features: {num_of_features}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (21620, 42, 36)\n",
      "This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): (21620, 42, 36) => True\n",
      "Shape of y_train_a: (21620, 12), this matches the desired shape (number_of_train_cases, target_act_length): (21620, 12) => True\n",
      "Shape of y_train_t: (21620,), this matches the desired shape (number_of_train_cases, ): (21620,) => True\n",
      "Shape of y_train_tr: (21620,), this matches the desired shape (number_of_train_cases, ): (21620,) => True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train,y_train_a, y_train_t, y_train_tr = inbu.generating_inputs(OCEL=enr_train,\n",
    "                                                                  num_of_features=num_of_features,\n",
    "                                                                  taf=target_act_feat,\n",
    "                                                                  act=act_feat,\n",
    "                                                                  custf=cust_feat,\n",
    "                                                                  divisor_next=divisor,\n",
    "                                                                  divisor_since=divisor2,\n",
    "                                                                  divisor_remaining=divisorTR)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): {(number_of_train_cases, max_trace_length, num_of_features)} => {X_train.shape ==(number_of_train_cases, max_trace_length, num_of_features)}\")\n",
    "print(f\"Shape of y_train_a: {y_train_a.shape}, this matches the desired shape (number_of_train_cases, target_act_length): {(number_of_train_cases, target_act_length)} => {y_train_a.shape ==(number_of_train_cases, target_act_length)}\")\n",
    "print(f\"Shape of y_train_t: {y_train_t.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_t.shape ==(number_of_train_cases, )}\")\n",
    "print(f\"Shape of y_train_tr: {y_train_tr.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_tr.shape ==(number_of_train_cases, )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = LSTM_model.LSTM_MODEL(X, y_a, y_t, y_tr,filename='orders_complete_enriched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# # summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
