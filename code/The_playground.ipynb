{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import (prep, folding, inbu, LSTM_model,setting)\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from jellyfish import damerau_levenshtein_distance, levenshtein_distance\n",
    "import pandas as pd\n",
    "import distance\n",
    "from sklearn import metrics\n",
    "np.random.seed(42)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_inputs = setting.inputdef()\n",
    "csvname = f\"{setting_inputs['flatten_by']}_complete\" if setting_inputs['complete'] else f\"{setting_inputs['flatten_by']}_filter\"\n",
    "# Define model_file based on single_log value\n",
    "model_file = f\"{csvname}_single\" if setting_inputs['single_log'] else f\"{csvname}_enriched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep the ocel and reading\n",
    "ocel, act_dict, cust_dict = prep.prep_ocel_complete(setting_inputs=setting_inputs,csvname=csvname)\n",
    "ocel_train, ocel_test = folding.folding_train_test(ocel, csvname= model_file)\n",
    "## define some static variables \n",
    "divisor = np.mean(ocel['Time_Diff'])  # average time between events\n",
    "divisor2 = np.mean(ocel['Time_Since_Start'])  # average time between current and first events\n",
    "divisorTR = np.mean(ocel['Remaining_Time'])  # average time instance remaining\n",
    "divisor3 = ocel.groupby('Case_ID')['Time_Since_Start'].apply(lambda x: (x.iloc[-1] - x).mean()).mean()\n",
    "\n",
    "print(f\"\\ndivisor: {divisor}\")\n",
    "print(f\"divisor2: {divisor2}\")\n",
    "print(f\"divisorTR: {divisorTR}\")\n",
    "print(f\"divisor3: {divisor3}\")\n",
    "print(f'Amount of rows of the OCEL: {len(ocel)}\\n')\n",
    "\n",
    "num_of_features, max_trace_length, act_feat,cust_feat, target_act_feat, target_act_feat_dict, other_features = setting.feature_dimensios(ocel=ocel,setting_input=setting_inputs)\n",
    "number_of_train_cases = len(ocel_train)\n",
    "target_act_length = len(target_act_feat)\n",
    "print(f\"Number of train cases: {number_of_train_cases}, Max trace length: {max_trace_length}, Number of features: {num_of_features}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train_a, y_train_t, y_train_tr = inbu.generating_inputs(ocel_train=ocel_train,ocel=ocel,setting_input=setting_inputs,\n",
    "                                                                  dn= divisor, ds= divisor2, dr= divisorTR)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"This matches the desired shape (number_of_train_cases, max_trace_length, num_of_features): {(number_of_train_cases, max_trace_length, num_of_features)} => {X_train.shape ==(number_of_train_cases, max_trace_length, num_of_features)}\")\n",
    "print(f\"Shape of y_train_a: {y_train_a.shape}, this matches the desired shape (number_of_train_cases, target_act_length): {(number_of_train_cases, target_act_length)} => {y_train_a.shape ==(number_of_train_cases, target_act_length)}\")\n",
    "print(f\"Shape of y_train_t: {y_train_t.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_t.shape ==(number_of_train_cases, )}\")\n",
    "print(f\"Shape of y_train_tr: {y_train_tr.shape}, this matches the desired shape (number_of_train_cases, ): {(number_of_train_cases, )} => {y_train_tr.shape ==(number_of_train_cases, )}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'For the following setting a model is now trained {model_file}\\n')\n",
    "history, best_model_name, early_stopping= LSTM_model.LSTM_MODEL(X_train, y_train_a, y_train_t, y_train_tr,filename=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = min(history.history['val_loss'])\n",
    "val_loss2 = best_model_name.best\n",
    "epoch = early_stopping.stopped_epoch - 49\n",
    "print(f'The best value for the validation loss is  {val_loss} and was archived at the epoch {epoch}\\n')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "modelname = 'model_' + model_file + f\"_{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "\n",
    "print(f'The best model has the name {modelname}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ocel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'./output_files/models/{modelname}')\n",
    "X_test, y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(ocel_fold=ocel_test,ocel=ocel,setting_input=setting_inputs,\n",
    "                                                                  dn= divisor, ds= divisor2, dr= divisorTR)\n",
    "\n",
    "# y_t = y_t * divisor3\n",
    "y = model.predict(X_test,verbose=1)\n",
    "y_char = y[0][:][:]\n",
    "y_t = y[1][:][:]\n",
    "y_tr = y[2][:][:]\n",
    "max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "y_t = np.maximum(y_t, 0)\n",
    "y_t1 = y_t * divisor\n",
    "y_tr1 = y_tr * divisorTR\n",
    "\n",
    "columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                ['Customers', 'Next_Time_Since_Start',\n",
    "                'Next_Time_Since_Midnight', 'Next_Weekday',\n",
    "                'Position', 'Time_Since_Midnight', 'Weekday'] + other_features\n",
    "\n",
    "columns_to_drop_existing = [col for col in columns_to_drop if col in ocel_test.columns]\n",
    "output_ocel = ocel_test.drop(columns=columns_to_drop_existing).copy()\n",
    "output_ocel['Pred_Activity'] = pred_act_list\n",
    "output_ocel['Pred_Time_Diff'] = y_t1\n",
    "output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "act_comp = output_ocel['Pred_Activity'] == output_ocel['Next_Activity'] \n",
    "print(f'The accuracy of the activation prediction is {sum(act_comp)/len(act_comp)}')\n",
    "MAE_Time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "MAE_rem_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "RMSE_Time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60),output_ocel['Next_Time_Diff']/ (24 * 60 * 60),squared=False)\n",
    "RMSE_rem_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60),output_ocel['Next_Remaining_Time']/ (24 * 60 * 60),squared=False)\n",
    "print(f'MAE of the time between events in days {MAE_Time_diff}')\n",
    "print(f'MAE of the remaining time in days {MAE_rem_time}')\n",
    "# print(f'RMSE of the time between events in days {RMSE_Time_diff}')\n",
    "# print(f'RMSE of the remaining time in days {RMSE_rem_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ocel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_lengths = range(2, max_trace_length-1)  # List of prefix lengths to consider\n",
    "results = []\n",
    "\n",
    "for prefix_length in prefix_lengths:\n",
    "    print(f\"Results for Prefix Length {prefix_length}:\")\n",
    "    \n",
    "    # Generate inputs with the current prefix length\n",
    "    X_test,y_test_a, y_test_t, y_test_tr = inbu.generating_inputs(ocel_fold=ocel_test,ocel=ocel,setting_input=setting_inputs,\n",
    "                                                                  dn= divisor, ds= divisor2, dr= divisorTR,\n",
    "                                                                    prefix_length=prefix_length)\n",
    "    # Make predictions with the model\n",
    "    y = model.predict(X_test, verbose=1)\n",
    "    y_char = y[0][:][:]\n",
    "    y_t = y[1][:][:]\n",
    "    y_tr = y[2][:][:]\n",
    "\n",
    "    max_index_list = [np.argmax(pred) for pred in y_char]\n",
    "    pred_act_list = [target_act_feat_dict.get(item, item) for item in max_index_list]\n",
    "    y_t = np.maximum(y_t, 0)\n",
    "    y_t1 = y_t * divisor\n",
    "    y_tr1 = y_tr * divisorTR\n",
    "\n",
    "    columns_to_drop = [col for col in ocel_test.columns if 'Act_' in col] + \\\n",
    "                    [col for col in ocel_test.columns if 'Cust_' in col] + \\\n",
    "                    ['Customers', 'Next_Time_Since_Start',\n",
    "                    'Next_Time_Since_Midnight', 'Next_Weekday',\n",
    "                    'Position', 'Time_Since_Midnight', 'Weekday'] + other_features\n",
    "\n",
    "    columns_to_drop_existing = [col for col in columns_to_drop if col in ocel_test.columns]\n",
    "    trace_length = ocel_test['Trace_Len'].values\n",
    "    output_ocel = ocel_test[trace_length >= prefix_length].reset_index(drop= True).drop(columns=columns_to_drop_existing).copy()\n",
    "    output_ocel['Pred_Activity'] = pred_act_list\n",
    "    output_ocel['Pred_Time_Diff'] = y_t1\n",
    "    output_ocel['Pred_Remaining_Time'] = y_tr1\n",
    "\n",
    "    output_ocel['Levenshtein'] = output_ocel.apply(lambda row: 1 - levenshtein_distance(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel.apply(lambda row: 1 - (damerau_levenshtein_distance(row['Pred_Activity'], row['Next_Activity']) / max(len(row['Pred_Activity']), len(row['Next_Activity']))), axis=1)\n",
    "    output_ocel['Damerau'] = output_ocel['Damerau'].clip(lower=0)\n",
    "    output_ocel['Jaccard'] = output_ocel.apply(lambda row: 1 - distance.jaccard(row['Pred_Activity'], row['Next_Activity']), axis=1)\n",
    "\n",
    "    mae_time_diff = metrics.mean_absolute_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60)) \n",
    "    mae_remaining_time = metrics.mean_absolute_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60)) \n",
    "    rmse_time_diff = metrics.mean_squared_error(output_ocel['Pred_Time_Diff']/ (24 * 60 * 60), output_ocel['Next_Time_Diff']/ (24 * 60 * 60), squared=False) \n",
    "    rmse_remaining_time = metrics.mean_squared_error(output_ocel['Pred_Remaining_Time']/ (24 * 60 * 60), output_ocel['Next_Remaining_Time']/ (24 * 60 * 60), squared=False) \n",
    "\n",
    "    # Store the results for the current prefix length\n",
    "    results.append({\n",
    "        'Prefix Length': prefix_length,\n",
    "        'length': len(y_tr),\n",
    "        'MAE Time Difference': mae_time_diff,\n",
    "        'MAE Remaining Time': mae_remaining_time,\n",
    "        'RMSE Time Difference': rmse_time_diff,\n",
    "        'RMSE Remaining Time': rmse_remaining_time\n",
    "    })\n",
    "\n",
    "    # Output additional values based on Case_ID and prefix length\n",
    "    for case_id in output_ocel['Case_ID'].unique():\n",
    "        case_data = output_ocel[output_ocel['Case_ID'] == case_id]\n",
    "        trace_length = len(case_data)\n",
    "        if prefix_length <= trace_length:\n",
    "            # print(f\"\\nAdditional values for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            case_data_prefix = case_data[:prefix_length]\n",
    "            #print(case_data_prefix.to_string(index=False))\n",
    "            \n",
    "            mae_time_diff_case = metrics.mean_absolute_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60))\n",
    "            mae_remaining_time_case = metrics.mean_absolute_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60))\n",
    "            rmse_time_diff_case = metrics.mean_squared_error(case_data_prefix['Pred_Time_Diff']/ (24 * 60 * 60), case_data_prefix['Next_Time_Diff']/ (24 * 60 * 60), squared=False)\n",
    "            rmse_remaining_time_case = metrics.mean_squared_error(case_data_prefix['Pred_Remaining_Time']/ (24 * 60 * 60), case_data_prefix['Next_Remaining_Time']/ (24 * 60 * 60), squared=False)\n",
    "            \n",
    "            # print(f\"\\nMetrics for Prefix Length {prefix_length} and Case ID {case_id}:\")\n",
    "            # print(\"MAE Time Difference:\", mae_time_diff_case)\n",
    "            # print(\"MAE Remaining Time:\", mae_remaining_time_case)\n",
    "            # print(\"RMSE Time Difference:\", rmse_time_diff_case)\n",
    "            # print(\"RMSE Remaining Time:\", rmse_remaining_time_case)\n",
    "\n",
    "# Output the overall results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "modelname = \"\"\n",
    "# Load the saved history from file\n",
    "with open(f'/ouput_files/history/{modelname}_history.pkl', 'rb') as file:\n",
    "    loaded_history = pickle.load(file)\n",
    "\n",
    "# Access the loaded history\n",
    "print(loaded_history)\n",
    "plt.plot(loaded_history['loss'])\n",
    "plt.plot(loaded_history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
